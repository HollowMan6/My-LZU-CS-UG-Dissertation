% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode

% \documentclass[AutoFakeBold]{LZUThesis}
\documentclass[AutoFakeBold]{LZUThesis}

\begin{document}
%=====%
%
%封皮页填写内容
%
%=====%

% 标题样式 使用 \title{{}}; 使用时必须保证至少两个外侧括号
%  如： 短标题 \title{{第一行}},  
% 	      长标题 \title{{第一行}{第二行}}
%             超长标题\tiitle{{第一行}{...}{第N行}}

\title{{基于 ICEEMDAN 多特征分解和}{Prophet 与 GRU 组合模型预测短期风速}}



% 标题样式 使用 \entitle{{}}; 使用时必须保证至少两个外侧括号
%  如： 短标题 \entitle{{First row}},  
% 	      长标题 \entitle{{First row}{ Second row}}
%             超长标题\entitle{{First row}{...}{ Next N row}}
% 注意：  英文标题多行时 需要在开头加个空格 防止摘要标题处英语单词粘连。
\entitle{{Forecast Short-term Wind Speed through ICEEMDAN}{ Decomposed Multi-features and Prophet \& GRU Hybrid Model}}

\author{蒋嵩林}
\major{计算机科学与技术（基础理论班）}
\advisor{任超}
\college{信息科学与工程学院}
\grade{2018级}



\maketitle

%==============================%
% ↓ ↓ ↓ 诚信说明页 授权说明书
%==============================%

% 1. 可以调整签字的宽度，现在是40
% 2. 去掉raisebox的相关注释(注意上下大括号对应)，可以改变-5那个数字调整签名和横线的上下位置

% 你的签名，signature.pdf 改为你的签名文件名，
\mysignature{
    % \raisebox{-5pt}{
        \includegraphics[width=60pt]{author_sig.pdf}
    % }
}
% % 你手写的日期，signature.pdf 改为你的手写的日期文件名
% \mytime{
%     % \raisebox{-5pt}{
%         \includegraphics[width=40pt]{signature.pdf}
%     % }
% }
% % 老师的手写签名，signature.pdf 改为老师的手写签名文件名
% \supervisorsignature{
%     % \raisebox{-5pt}{
%         \includegraphics[width=40pt]{signature.pdf}
%     % }
% }
% % 老师手写的时间，signature.pdf 改为老师的手写的日期文件名
% \teachertime{
%     % \raisebox{-5pSt}{
%         \includegraphics[width=40pt]{signature.pdf}
%     % }
% }
% % 老师手写的成绩
% \recommendedgrade{
%     % \raisebox{-5pt}{
%         \includegraphics[width=40pt]{signature.pdf}
%     % }
% }

\makestatement

%==============================%
% ↑ ↑ ↑ 诚信说明页 授权说明书
%==============================%


%=====%
%论文（设计）成绩：注意2007的模板要求，成绩页在最后，2021要求成绩页在摘要前面
%=====%

% 下面这些注释掉可以去掉成绩、评语什么的
\supervisorcomment{}


\committeecomment{}

\finalgrade{}
% 上面这些注释掉可以去掉成绩、评语什么的

\Grade %这一句才是成绩页，上面是填写


\frontmatter



%中文摘要
\ZhAbstract{
气候变化和环保问题关乎人类未来命运。在石油危机以及全球变暖问题愈发严重的现在，
可再生清洁能源相关研究成为了学界的关注热点。风能，作为触手可得的一种能源，正成为新能
源的主力军之一。准确预测风速，从而保证电网的稳定性，具有十分重大的意义。风速预测
是一个时间序列回归问题，由于风速的波动具有随机性，其影响因素也十分复杂，呈现出
非平稳且非线性的特征，因而对短期风速的预测难度较大。

本文选取数值天气预报中常见的六种气象要素历史数据，包括近地面气温、近地面气压、
近地面空气比湿、地面向下短波辐射、地面向下长波辐射、地面降水率，结合近地面全
风速的历史数据构建短期风速的预测模型。首先，采用当前科研最前沿的改进自适应噪声完备
集合经验模态分解（ICEEMDAN）算法，对上述七种特征历史数据进行分解，将高频噪声和
低频信号进行分离，降低时间序列数据分析的复杂度，从而提高准确性。然后，将分解结
果序列输入由 Facebook 推出的主流时间序列预测框架 Prophet 进行预测以及统计分
析，得到Prophet拟合预测的结果以及统计分析预测得出的趋势分量、累加式季节性分量
、日分量、年分量以及上述分量所对应的预测最大边界和最小边界，进一步降低七种特征
对应时间序列的复杂度，便于神经网络的训练。最终，将所有由 Prophet 分析预测的时
段对应的结果以及分量进行基于径向基函数的核主成分分析（KPCA），将数据升维，分解
非线性相关，更进一步降低数据复杂度。然后输入进一个由三层门控循环单元（GRU）构成
的深度学习模型，采用最新科研成果 Nadam 优化器 以及 Huber损失函数训练模型，并部
分应用GELU激活函数，输出预测的时段对应的近地面全风速，从而来预测实际的短期风速。

为了验证模型的实际效果，本文选取了甘肃中电酒泉第四风力发电有限公司附近（北纬
40.65 度，东经 96.95 度）的2017年1月1日0时整至2018年12月31日21时整
\footnote{此处所述时间均为协调世界时(UTC, Universal Time Coordinated)。}间
隔三小时的历史数据，使用均方误差（MSE）、平均绝对误差（MAE）、平均绝对误
差百分比（MAPE）、均方根误差（RMSE）、决定系数（$R^2$）等多项指标，以及对模型的预
测结果进行可视化分析，与只使用近地面全风速历史数据、未进行时间序列分解剔除噪声、
只使用单一模型的情况进行对比，对模型全方面综合评估。结果表明，使用本文提出的模型
，预测短期风速的精度会明显提升，因而具有优越性。
}{风速影响因素，短期风速预测，组合模型，改进自适应噪声完备集合经验模态分解，Prophet，门控循环单元神经网络，深度学习，数据科学}


%英文摘要
\EnAbstract{\fontspec{Times New Roman} {
Climate change and environmental issues matter the destiny of humankind.
With the oil crisis and global warming worsening, renewable energy-related
research has become a hot spot attracting great academic attention. Wind is
becoming mainstream renewable energy as a readily available energy source.
As a result, it is essential to predict the wind speed accurately to ensure
power system stability. Wind speed forecast is a time series regression
problem. Due to the randomness of wind speed fluctuations, influencing
factors for wind speed are very complex. The wind speed has non-stationary
and nonlinear characteristics, so it is difficult to predict short-term wind
speed.

This paper selects the historical data of six common meteorological
elements in numerical weather prediction, including near-surface air
temperature, near-surface air pressure, near-surface specific humidity,
surface downwelling shortwave radiation, surface downwelling longwave
radiation, and surface precipitation rate. Combine historical time series
data of near-surface total wind speed with the aforementioned elements
and build the short-term wind speed, forecasting model. Firstly, the
ICEEMDAN (Improved Complete Ensemble Empirical Mode Decomposition with
Adaptive Noise) algorithm, which is at the forefront of current scientific
research, decomposes the above seven elements' historical data. The
decomposition can separate high-frequency and low-frequency signals,
which eventually reduces the complexity of time series data analysis
and improves accuracy. Then, input the decomposed sequence into Prophet,
a mainstream time series forecasting framework developed by Facebook,
for forecasting and statistical analysis. Obtain the result of Prophet
fitting prediction, the trend component, additive seasonality component,
daily component, yearly component, as well as maximum and minimum boundaries
of above. These features further help reduce the complexity of the time
series corresponding to the seven meteorological elements and facilitate
the training of the neural network. Finally, all the predictions and
components corresponding to the time series elements predicted by the
Prophet analysis are first performed a Kernel Principal Component Analysis
(KPCA) with radial basis function, so as to upscale the data dimension and
decompose nonlinear correlations to further reduce data complexity. Then 
input the data into a deep learning model composed of a three-layer
Gated Recurrent Unit (GRU). Use the latest scientific research results Nadam 
optimizer and Huber loss function as well as GELU activation function to 
train the model. Output the near-surface total wind speed corresponding to the
predicted period so that the actual short-term wind speed can get predicted.

In order to verify the actual effect of the model, this paper selects the
historical data at a location near Gansu Zhongdian Jiuquan Fourth Wind Power
Co., Ltd. (latitude 40.65 degrees north, longitude 96.95 degrees east) from
0:00 on January 1, 2017, to 21:00 on December 31, 2018, 
\footnote{The times mentioned here are all in UTC (Universal Time Coordinated). }
at three-hourintervals. Using various evaluating indicators like Mean Squared
Error (MSE), Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE),
Root Mean Squared Error (RMSE), Coefficient of Determination ($R^2$), etc.
for verification. The predicted results are visualized and compared with the
case of only using the near-ground full wind speed historical data, without
time series decomposition to remove noise, and only using a single model.
The model is comprehensively evaluated in all aspects. The results show
that using the model proposed in this paper, the accuracy for predicting
short-term wind speed will be significantly improved, so it has supremacy.
}}
{wind speed influencing factors; short-term wind speed forecast; 
hybrid model; ICEEMDAN; Prophet; GRU; deep learning; data science.
}

%生成目录
\tableofcontents
% \thispagestyle{empty}


%文章主体
\mainmatter

\chapter{绪 \qquad 论}

% ！学校要求的规范，绪论是单独的，不是第一章，但是老师们都是让作为第一章，这里我把它放在了论文里，如果你要让在外面，只需要把上面的 \mainmatter 这一句话放在“绪论内容后面，正文第一章前面”即可，也就是 \chapter{latex部分用法简介} 这一句话上面

% \Intro{
\section{选题研究背景及意义}
\subsection{风力发电的前景}
随着工业发展的需要，人类社会对能源的依赖度也在逐步上升。第二次能源革命以来，
传统化石燃料的使用导致了一系列的问题。化石燃料在开采过程中也产生了
一系列的环境问题。以煤炭为例，在开采时，会破坏地表原本的性状，引发滑坡，塌陷
等一系列问题。开采煤炭所产生的废渣也难以处理，产生的污水会对水土环境造成污染。
同时，燃烧化石燃料所产生的二氧化硫($SO_2$)和氮氧化物会形成酸雨、粉尘使空气能
见度降低、一氧化碳(CO)和芳香烃化合物会污染空气。二氧化碳($CO_2$)在大气层中所
占比例的提高，也导致了温室效应与气候变化，从而使得一些极端天气灾害的发生频率
有了显著的升高。然而目前，在世界能源消费占比中，煤炭和石油的比重仍较重要。
我国的能源生产和消费构成中，煤炭在2019年仍在一次能源中占比57.7\%，占据着
主要地位。\cite{能源数据2021王庆一}

当前传统化石燃料，由于其储量的有限性，也正逐步面临枯竭的风险。“绿水青山就
是金山银山”。可再生能源的发展，不仅将会确保绿水青山的存在，而且同时也必然即
将成为金山银山的重要组成部分。过去三十年以来，风能一直保持着最快增长的可再
生能源的记录，是目前全球第二大的可再生能源。风能本质上属于一种气象能源，其
为太阳照射环境下地球表面受热不均，在水平气压梯度力的影响下，由于温差造成大
气对流所产生的一种能量来源。李仲蔚的研究
\cite{李仲蔚2019风力发电企业价值评估研究}估算结果表明，全球可开发
利用的风能资源达到了二百万兆瓦($2\times10^7MW$)，是目前全球第一大的可再生
能源水能的10倍。风能因其分布广泛，弥补了水能发电需要的苛刻条件以及对生态自
然环境可能造成不良影响的缺陷。如将预估的可利用风能的1\%加以利用，即可以满
足全球能源的发电使用需求，因而发展潜力极其巨大，十分有望在将来替代水能成为
全球第二大的可再生能源。

\subsection{短期风速预测的意义}
短期风速的主要影响因素分为气象因素和地形因素。其中，气象因素主要包括温度、气压、
湿度等，而地形因素包括地貌、地表障碍等。

对于短期近地面风速的预测能够很好的帮助并促进风能的应用。首先，风力发电厂管理人员
可以通过预测结果优化电力分配，提高发电量；其次，风力发电厂还可以准确的在风速
过大之前对风力发电机指示停机，预防风力发电机的过载损毁，避免或者减少相应的损
失；最后，还可以有效安排好风力发电的电网并网问题，减少因为风速的剧烈波动对电
网电业的稳定性影响，降低运营成本，增加风电场的效益。

对于目前的风速预测研究而言，相关问题主流使用的模型包括传统时间序列模型以及
深度学习模型。他们各自都存在一定的优点和缺陷，单一模型并不能很好的进行预测
\cite{陆冰鉴2020基于}。同时，由于风速数据中往往包含着较大的噪声问题，如何
有效地对其数据集进行降噪处理也是目前研究的方向。由于单一的预测方法无法做到
很好的风速预测，如果能通过组合模型，对其进行精确的预测，将会对风力发电的应
用起到巨大的促进作用。

\section{选题已有研究成果综述}
\subsection{数值预报方法}
数值预报方法使用大气压、气温、相对湿度、风速等数值型数据来作为初始状态，
以流体力学方程和热力学方程为依据来实现整个大气状态模型的构建，通过超级
计算机进行数值计算求解，得到未来天气的预报结果。
\cite{姜兆宇2019多时空尺度的风力发电预测方法综述}

目前数值预报方法已经很成熟，准确性良好，已经广泛地应用到了天气预报中。
但是，由于数值方法需要占用大量的计算资源，难以将时间和空间分辨率
都做得很高，且短期风速中蕴含的噪声较大，因而单纯的数值预报一般不适用于短期风速预报。
朱智慧等人\cite{朱智慧2010T639}基于T639全球中期数值预报产品得到的上海
南汇站24小时风速预报结果利用逐步回归分析、结合Kalman滤波得出的MOS方程
进行订正，结果表明其订正后的精度可以考虑投入实际使用。夏晓玲等人
\cite{夏晓玲2019贵州省数值预报风速产品检验及订正}利用数值预报的
ECWMF，GRAPES和JAPAN模式对于贵州省范围内84个站点的风速预报进行了分析，最终
运用神经网络对3种模式风速预报进行订正，结果表明其误差，正确率订正改善效果
明显，但是相关系数的提高较小。

\subsection{统计与传统机器学习方法}
不同于数值预报方法，统计与传统机器学习方法基于风速历史数据的时间序列，
通过训练机器学习模型来预测未来天气，并且可以对数据进行预处理，从而可以
从历史数据中挖掘出风速数据的潜在规律，因而相对于数值预报方法，模型的训练
和预测更加简单，无需使用超级计算机进行大量的计算。

\begin{itemize}
\item[a. ] 统计方法：
\end{itemize}

经典的统计方法中对于时间序列数据的处理一般采用自回归综合移动平均模型
（ARIMA, AutoRegressive Integrated Moving Average）。其采用过去观
测值的线性函数关系预测未来值。由于风速的时间序列数据普遍是非平稳的，
包含了很强的季节性，因此相关研究普遍采用季节性自回归综合移动平均模
型（SARIMA, Seasonal AutoregRessive Integrated 
Moving Average）SARIMA是Box和Jenkins提出的ARIMA模型的一个扩展，
用于处理具有季节特征的时间序列数据。Sun, R. N.等人\cite{2017Forecast}
基于ARIMA和SARIMA模型提前24小时预测小时平均风速和风力发电量。并进行了
平均相对误差的比较分析。结果表明，SARIMA模型的预测效果明显优于ARIMA模型。

SARIMA本身机理决定了SARIMA无法处理非线性
时间序列特征，因而在呈现出非平稳且非线性特征的风速时间序列预测中表现
并不是很好。Haddad等人\cite{haddad2019wind}基于SARIMA方法构建了一个
太阳能和风能预测模型，对于风能预测而言最终效果不是很突出。
Xl, A等人\cite{2021Short}使用SARIMA模型来预测苏格兰沿海地区
的每小时实测风速。结果表明尽管SARIMA在风速预测的性能准确度比方面
相对于循环神经网络方法具有优越性，但是其预测的风速准确度并不是很理想。

\begin{itemize}
\item[b. ] 机器学习方法：
\end{itemize}
 
传统机器学习方法，在风速中应用最广泛的为支持向量回归机（SVR，
Support Vector Regression）。支持向量回归机是支持向量机
（SVM，Support Vector Machine）的一个非常重要的变体，其将SVM
的应用领域从分类变成了回归。SVR的目标是对时间序列输入数据的每个点
通过非线性变换寻找一个最优超平面。不同于SVM的最优超平面需要使得两类
或多类样本点与超平面之间的总偏差最大，SVR的样本点最终只有一类，
并且其最优超平面需要所有的样本点与超平面之间的总偏差最小。

传统的SVR能够对非线性特性的数据有较好的预测能力，然而由于风速呈现
出非平稳的特征，其中所含噪声较多，直接对风速进行预测无法达到很好的
效果。朱霄旬等人\cite{朱霄旬2017遗传算法对}使用一种基于遗传算法
(GA，Genetic Algorithm)的多参数同步优化算法，改进了传统通过相空
间重构法求出SVR预测模型的最优参数的方法，并大大提高了预测精度。
Pan, C.等人\cite{2018Hybrid}首先根据回归率和确定性相结合的联合指数，
对风速序列的可预测性进行了定量分析，然后利用联合指数优化的参数重建风速
序列，通过嵌入维数和延迟时间得到预测模型的最佳输入集。最终利用布谷鸟优化
算法（COA，Cuckoo Optimization Algorithm）优化的SVR模型对风速进行预
测，取得了不错的效果。

\subsection{深度学习方法}

近年来，随着深度学习的发展，深度学习方法在风速预测中的应用越来越广泛。
深度学习由数据驱动，具有十分强大的泛化能力，十分适合处理具有非平稳且
非线性特征的风速时间序列预测。神经网络模型虽然预测效果好，但是
存在训练难度大的问题，对数据集和参数的要求十分高，否则
容易产生过拟合、梯度爆炸、梯度消失等一系列问题。

Shivani等人\cite{Shivani2019A}对传统时间序列统计模型ARIMA和
一个深度学习模型预测风速进行了比较研究。该深度学习模型由长短期记忆网络
（LSTM，Long Short-Term Memory）和循环神经网络
（RNN，Recurrent Neural Network）组合而成，结果凸显了深度学习预测风速
的优越性。Alencar, D. B.等人\cite{alencar2018hybrid}提出了一种基于
SARIMA和反向传播（BP，Back Propagation）神经网络的组合模型方法，
用于多步超前风速预测。并进行了仿真分析。其结果表明，对于不同的预测时段，
该组合模型预测方法的预测精度优于大部分传统算法。朱丽娜的研究
\cite{朱丽娜2021风电}得出结论：LSTM适用于预测非平稳序列风速，Elman神经
网络，一种动态递归神经网络，次之。

\subsection{降噪方法}
由于风速数据的非平稳性，其时间序列数据中往往参杂着较大的噪声。这些噪声
如果不加以平滑处理从而去除，将会严重影响到模型对风速时间序列的预测精度
和泛化能力，加大对其非线性关系的学习难度。许多常见的信号分解技术包括傅里叶
变换以及小波变换，将时间序列信号从时域变换到频域，从而将高频噪声剔除。
常见的降噪方法包括小波分解（WD，Wavelet Decomposition）、
变分模式分解（Variational Mode Decomposition）、Hilbert-Huang变换
（HHT，Hilbert-Huang Transform）以及经验模式分解
（EMD，Empirical Mode Decomposition）以及基于上述四类方法演化出的
一系列分支。

谢义超\cite{谢义超2021基于}提出了一种基于CEEMDAN分解和改进的LSTM模型。
该模型基于粒子群优化算法（PSO，Particle Swarm Optimization）与样本熵
选择CEEMDAN以及LSTM的超参数，从而让参数达到最优值。最终得出的结果表明，
CEEMDAN分解技术可以极大地提高基于循环神经网络模型的泛化能力，降低模型
的训练难度。王秀的研究\cite{王秀2021基于}基于小波变换，通过SARIMA和
LSTM模型的组合，提升了对短期风速的预测精度。

\section{论文研究内容与组织结构}

随着数据科学的发展，使用开箱即用（Out of the box）的数据分析框架
已经成为数据科学研究的一种新潮流。在这之中包括了流行的机器学习框架
scikit-learn，以及时间序列数据处理预测框架Prophet。

由于注意到直接使用Prophet框架来进行非平稳非线性的风速预测效果并不佳，因而
本文基于上述前人研究成果，决定选用ICEEMDAN分解技术，并使用当前最新循环神经
网络结构GRU，结合Prophet框架，形成ICEEMDAN-Prophet-GRU模型。同时结合数值
预报方法提供的灵感，将其他天气要素特征也输入到模型中，提高模型的泛化能力，
最终验证模型的优越性。论文的结构如下：

第一章：绪论。主要讲述选题缘由，风速问题研究背景以及意义，以及对现有研究
方法的综述。

第二章：数据来源及特征提取。主要讲述特征的选取原因以及数据集的制作过程，并
对选取数据集的性状进行了分析，并通过统计学方法验证特征选取的正确性。

第三章：使用技术的介绍和比较。主要讲述现有主流技术，并进行技术分析对比，讲述
最终选择ICEEMDAN分解技术、Prophet、基于RBF的KPCA、GRU网络、Nadam 优化器、
Huber损失函数以及GELU激活函数的原因。

第四章：模型的建立和评估。主要讲述模型的评估指标介绍、模型的细节、训练以及调参
过程、与普通使用模型的情况进行对比。

第五章：总结与展望。对全文进行总结，指出创新点与有待进一步研究的方向。

% }


% % =======正文从第一章开始
% \setcounter{chapter}{0}

\chapter{数据来源及特征选取}
\section{数据来源}
本文数据来源于中国区域地面气象要素驱动数据集（1979-2018）
\cite{8028b944-daaa-4511-8769-965612652c49}，该数据集常用于数值天气
预报。该数据集包括近地面气温、近地面气压、近地面空气比湿、近地面全风速、
地面向下短波辐射、地面向下长波辐射、地面降水率共7个气象要素。数据时间
分辨率为3小时，水平空间分辨率为0.1°，为netCDF格式。
\cite{37cab0ac-d066-4fb9-aa9c-1cf50d601096}

该数据集基于世界上现有的GLDAS数据、普林斯顿再分析数据、GEWEX-SRB辐射
数据和TRMM降水数据，并整合了中国气象局的常规气象观测数据。原始数据来
自卫星遥感数据、再分析数据与气象局的观测数据，并去除了非物理范围值，
对于缺失数据采用ANUSPLIN统计插值。该数据集的精度介于气象局的观测数据
和卫星遥感数据之间，优于世界上现有的再分析数据。\cite{6bab74c1-f2dd-4e24-a833-81f33bedf9b1}

\section{特征选取与数据集的制作}
由于气象要素之间都是紧密相关的，本文数据集基于上述中国区域地面气象要素驱动数据
集（1979-2018）构建而成，通过Python语言netCDF4库
\footnote{提取所用代码请见附录部分A.1}
选取了数据集中的全部气象要素，并选择了甘肃中电酒泉第四风力发电有限公司附近
（北纬40.65 度，东经 96.95 度）的2017年1月1日0时整至2018年12月31日21时整
\footnote{此处所述时间均为协调世界时(UTC, Universal Time Coordinated)。}
共5840条数据。生成数据格式为CSV（逗号分隔值，Comma-Separated Values）文件，包
含数据内容如下：

\begin{table}[H]
    \centering
    \caption{选取特征说明}
    \begin{tabular}{cccc}
    \toprule
    特征 & 名称 & 单位 & 含义 \\
    \midrule
    ds & 日期 & UTC & 数据格式为：YYYY-mm-dd HH:MM:SS \\
    lrad & 地面向下长波辐射 & $W/m^2$ & 从当前时间1.5小时前开始的3小时平均值 \\
    prec & 地面降水率 & $mm/h$ & 从当前时间3小时前开始的3小时平均值 \\
    pres & 近地面气压 & $Pa$ & 近地面(距地面2米处)瞬时值 \\
    shum & 近地面空气比湿 & 比值，无单位 & 近地面(距地面2米处)瞬时值 \\
    srad & 地面向下短波辐射 & $W/m^2$ & 从当前时间1.5小时前开始的3小时平均值 \\
    temp & 近地面气温 & $K$ & 近地面(距地面2米处)瞬时值 \\
    wind & 近地面全风速 & $m/s$ & 近地面(距地面2米处)瞬时值 \\
    \bottomrule
    \end{tabular}
    \label{features}
\end{table}

\section{特征数据分析}
\subsection{描述性统计分析}

\begin{table}[H]
    \centering
    \caption{七种气象要素的描述性统计分析$^1$}
    \begin{tabular}{cccccccc}
    \toprule
    指标 & lrad & prec & pres & shum & srad & temp & wind \\
    \midrule
    算术均值 & 269.37 & 0.0089 & 85520.87 & 0.00299 & 192.830351 & 281.409456 & 4.03706 \\
    标准差 & 64.847 & 0.0859 & 611.25746 & 0.002662 & 267.654341 & 13.825424 & 2.358024 \\
    最小值 & 132.25 & 0 & 83722 & 0.000015 & 0 & 245.62999 & 0.051998 \\
    25\%值 & 216.25 & 0 & 85050 & 0.001126 & 0 & 270.3075 & 2.281998 \\
    50\%值 & 265.5 & 0 & 8552 & 0.001964 & 3 & 282.73499 & 3.528997 \\
    75\%值 & 321 & 0 & 85974 & 0.004003 & 351.9375 & 292.57 & 5.257996 \\
    最大值 & 449.5 & 2.6925 & 8682 & 0.015863 & 989.5 & 311.25 & 16.23 \\
    极差 & 317.25 & 2.6925 & 3098 & 0.015848 & 989.5 & 65.62001 & 16.178002 \\
    四分位差 & 104.75 & 0 & 924 & 0.002878 & 351.9375 & 22.2625 & 2.975998 \\
    离散系数 & 0.2407 & 9.6161 & 0.007147 & 0.890314 & 1.38803 & 0.049129 & 0.584095 \\
    平均离差 & 54.755 & 0.0164 & 508.7419 & 0.002045 & 223.389189 & 11.77691 & 1.845357 \\
    偏态 & 0.1805 & 19.283 & 0.002316 & 1.564872 & 1.212509 & -0.236851 & 1.115394 \\
    峰度 & -0.8743 & 443.99 & -0.726484 & 2.039496 & 0.206402 & -0.895183 & 1.404608 \\
    \bottomrule \\
    \end{tabular} \\
    \footnotesize{$^1$ 该表格数据生成代码见附录部分A.2} \\
    \label{analysis}
\end{table}

由表\ref{analysis}统计数据可见，选址地（甘肃中电酒泉第四风力发电有限公司附近
，北纬40.65 度，东经 96.95 度）处2017-2018年两年全年最低气温-27.5摄氏度，
最高38.1摄氏度，温差较大，冷热对流明显。同时该地区降水非常稀少，空气干燥，太阳
辐射强，易产生空气的稳定辐射型对流。该地区出现过的最大风力为7级（16.23 m/s），
风力平均为3级（4.04m/s），因而风速较大，且风速的方差较小，风力资源丰富且平稳，
的确是风力发电的一个很好的选址。

\subsection{相关性分析和显著性检验}
因为传统的皮尔逊（Pearson）相关系数衡量的只是线性相关关系，并且皮尔逊相关系数
对数据的要求较高，不适用于非平稳且非线性的风速数据。因而这里采用可以度量单调关
系的斯皮尔曼（Spearman）相关系数。

\begin{table}[H]
    \centering
    \caption{风速与其他六种气象要素的斯皮尔曼相关性分析$^1$}
    \begin{tabular}{ccccccc}
    \toprule
    wind & 相关系数 & 显著水平 \\
    \midrule
    lrad & $0.03528229315199814^{**}$ & 0.0070065793090313055 \\
    prec & $0.008443728183433091$ & 0.5188350558375361 \\
    pres & $0.07156398261497926^{**}$ & $4.3810149807651604\times10^{-8}$ \\
    shum & $-0.08302721983053592^{**}$ & $2.0904230457715092\times10^{-10}$ \\
    srad & $0.24649937697179994^{**}$ & $1.4389507268798562\times10^{-81}$ \\
    temp & $0.05948229496676412^{**}$ & $5.398211275459676\times10^{-6}$ \\
    \bottomrule \\
    \end{tabular} \\
    \footnotesize{$^1$ 该表格数据生成代码见附录部分A.3} \\
    \footnotesize{$^{**}$ 表示在0.01级别（双尾），相关性显著} \\
    \label{relativity-analysis}
\end{table}

由表\ref{relativity-analysis}所示，排除由于选址地区降水数据过于稀少，导致地面降水率与其相关性不大的因素，
风速与其他剩余五种气象要素的相关系数都较大，有较强的相关性，并且相关性都在99\%
的置信水平下通过检验，相关性极其显著。其中与风速相关性最强的是地面向下短波辐射。



\chapter{使用技术的介绍和比较}
\section{基于EMD的信号分解技术}
\subsection{EMD}
经验模态分解（EMD，Empirical Mode Decomposition）是一种适用于处理非平稳
非线性时间序列的自适应时空分析方法，由Huang, Norden E等人于1998年
提出\cite{huang1998empirical}。EMD在不离开时域的情况下将序列划分为
有限个本征模函数（IMF，Intrinsic Mode Function）和残差的操作。分解出的IMF
可以提供一个时间序列中包含的各种信号的特征。与傅里叶变换和小波分解等类似，
EMD分解不是基于物理性质。但是，EMD依据信号自身的时间尺度特征对信号没有任何
先验主观标准选择的进行自动分解，因而无需像傅里叶变换与小波分解一样设定谐波
基函数或小波基函数。

在时域范围内具有以下条件特征的时间序列，可以使用EMD分解：
\begin{itemize}
\item 局部的时域特性仅由极值点间的时间尺度唯一确定。
\item 至少存在一个极大值点和一个极小值点。
\item 若存在拐点但无极值点，可通过多次微分求得极值，然后积分计算分解结果。
\end{itemize}

分解出的本征模函数在时域范围内满足如下两个性质：
\begin{itemize}
\item 极值点和过零点的数目相等或相差一个。
\item 上包络线（极大值点的包络线）和下包络线（极小值点的包络线）均值为0。
\end{itemize}

EMD分解步骤如下：
\begin{itemize}
\item[1. ] 找出待分解时间序列$X(t)$的所有极大值点，并将所有极大值点用三次样条差值
函数拟合形成原数据的上包络线。
\item[2. ] 同理，找出待分解时间序列$X(t)$的所有极小值点，并将所有极小值点用三次样
条插值函数拟合形成数据的下包络线，
\item[3. ] 设上包络线和下包络线的均值函数为$M(t)$，设$X(t)-M(t)=H(t)$，得到新的
时间序列$H(t)$。如果$H(t)$不满足本征模函数的两个性质，则对$H(t)$重复步骤
1-3，否则得到一个IMF分量$H(t)=IMF_i(t)$。
\item[4. ] 对$M(t)$重复步骤1-3，直到$M(t)$不满足使用EMD分解
的条件，则$M(t)=R(t)$，R(t)为残差。
\end{itemize}

由上述推导过程可得：
$$
X(t)=\displaystyle\sum_{i=1} ^n IMF_i(t) +R(t)
$$

\subsection{EEMD}

集成经验模态分解（EEMD，Ensemble Empirical Mode Decomposition）是一种
噪声辅助数据分析方法，包含了用于筛选的白噪声附加时间序列。
EEMD由Wu, Zhaohua等人提出\cite{wu2009ensemble}。他们的
研究发现，在EMD分解的IMF分量筛选过程中，添加一定的白噪声可以平滑极值点的分布，
从而让分解的结果更加健壮。使分解出的时间序列在适当的本征模函数（IMF）中进行比较
，从而能够让分解过程考量到尽多可能的解并进行筛选。由于EMD是一种时空分析方
法，因此白噪声可以通过足够多的平均迭代抵消，从而在此平均化过程中唯一留存下来的
部分就是更真实且更具物理意义的时间序列。

EEMD分解步骤如下：
\begin{itemize}
\item[1. ] 对待分解时间序列$X(t)$添加一个随机白噪声序列$N(t)$，得到新序列$K(t)$。
\item[2. ] 对$K(t)$进行EMD分解。
\item[3. ] 对步骤1-2重复n次，将得到的共计n组的每个IMF分量和R按组进行系综平均（Ensemble Average）。
\item[4. ] 得到系综平均后的IMF分量和R，公式同EMD分解。
\end{itemize}

\subsection{CEEMDAN}
自适应噪声完备集合经验模态分解（CEEMDAN，Improved Complete Ensemble
Empirical Mode Decomposition with Adaptive Noise) 由Torres
等人提出\cite{torres2011complete}。它是EMD的改进版本，
同时又借鉴了EEMD的思想，提供了对原始信号的精确重建和对本征模函数（IMF）的
更好的频谱分离。

CEEMDAN分解步骤如下：
\begin{itemize}
\item[1. ] 对待分解时间序列$X(t)$添加一个幅值为r白噪声序列$N(t)$，得到新序列$K(t)$。
\item[2. ] 对$K(t)$进行一次EMD分解迭代，得到一个IMF分量。
\item[3. ] 对步骤1-2重复n次，将得到的共计n组的IMF进行系综平均（Ensemble Average），得到$IMF_i(t)$
用$X(t)-IMF_i(t)$作为新序列，返回步骤1迭代j次。
\item[4. ] 最终不能进行EMD分解时$X(t)-IMF_i(t)$得到残差R，公式关系同EMD。
\end{itemize}

CEEMDAN相较于EEMD方法有如下优点：

\begin{itemize}
\item EEMD方法需要通过足够多的平均迭代抵消白噪声，因而将所有IMF分量和
残差R直接相加复原出的原信号并不准确。而CEEMDAN在较小的平均次数下就可以有很好
的可复原性。
\item 相较于EEMD，CEEMDAN无需计算过多的平均值，因而分解的性能要更高。
\item EEMD分解一般会出现多个无意义的低幅值低频伪IMF分量，CEEMDAN可以减少该种情况
出现的频率。
\end{itemize}

\subsection{ICEEMDAN}

ICEEMDAN由Colominas等人提出\cite{colominas2014improved}，其为CEEMDAN的改进版本。
ICEEMDAN将上述步骤3的重复迭代过程中的第x次迭代时使用的噪声更改为原第一次添加噪声的
的对噪声的EMD分解的第x个IMF分量乘以添加噪声相对于待分解时间序列的信噪比，再除以白噪
声的标准差。

ICEEMDAN分解相对于CEEMDAN进一步降低了出现多个无意义的低幅值低频伪IMF分量的频率。

由于ICEEMDAN是基于EMD的信号分解技术的集大成者，因而本文最终决定选用ICEEMDAN。

\section{基于统计学的时间序列预测方法}
\subsection{SARIMA}
SARIMA模型一般分为简单季节模型和乘积季节模型：

\begin{itemize}
\item[1. ] 简单季节模型：

简单季节模型是指序列中的季节效应和其它效应之间是加法关系：
$$x_t=S_t+T_t+I_t$$

简单季节模型通过简单的趋势差分、季节差分之后序列即可转化为平稳，
它的模型结构通常如下：
$$\nabla_D\nabla^dx_t=\frac{\Theta(B)}{\Phi(B)}\varepsilon_t$$

其中:
$$
\begin{matrix}
\nabla_Dx_t=\left(1+B^D\right)X_t,{\ }\nabla^dx_t=\left(1-B^D\right)X_t\\
\Theta(B)=1-\theta_1B-\theta_2B^2-\cdots-\theta_qB^q\\
\Phi(B)=1-\varphi_1B-\varphi_2B^2-\cdots-\varphi_pB^p\\
\end{matrix}
$$

\item[2. ] 乘积季节模型：

由于序列的季节效应、长期趋势效应和随机波动之间有着复杂的相互关联性，
简单的季节模型不能充分地提取其中的相关关系。乘积季节模型的构造原理是，
短期相关性用低阶 ARMA(p,q) 模型提取，季节相关性用以周期步长s为单位
的 ARMA(p,q) 模型提取，假设短期相关和季节效应之间具有乘积关系，
模型结构如下:
$$\nabla^d\nabla_S^Dx_t=\frac{\Theta(B)}{\Phi(B)}\frac{\Theta_S(B)}{\Phi_S(B)}\varepsilon_t$$

由于短期相关性和季节效应之间具有乘积关系，所以，可以将差分后的序列拟合成 ARMA(p,q) 模型和 ARMA(p,q) 
模型的乘积形式，最终原序列乘积季节模型的完整结构可采取如下表达式：
$$\Phi(B)\Phi_S(\mathrm{\ }B)\nabla_S^D\nabla^dx_t=\Theta(B)\Theta_S(B)\varepsilon_t$$

其中：
$$
\begin{matrix}
\nabla^dx_t=(1-B)^dx_t,\nabla_S^Dx_t=\left(1-B^S\right)^Dx_t\\
\Phi(B)=1-\varphi_1B-\varphi_2B-\cdots-\varphi_pB^p\\
\Theta(B)=1-\theta_1B-\theta_2B^2-\cdots-\theta_qB^q\\
\Phi_S(B)=1-\varphi_1B^S-\cdots-\varphi_PB^{PS}\\
\Theta_S(B)=1-\theta_1B^S-\cdots-\theta_QB^{QS}\\
\end{matrix}
$$

该乘积季节模型通常简记为$SARIMA(p,d,q)\times(P,D,Q)_S$。
\end{itemize}

使用 SARIMA 进行模型构建主要有三个主要步骤，分别为平滑处理、平稳性检验
以及时间序列定阶\cite{Foneone2019时间序列}：

\begin{itemize}
\item 由于SARIMA需要时间序列满足平稳性和非白噪声的要求，所以要首先用差分法
和平滑法（滚动平均和滚动标准差）来实现序列的平稳性操作，并确定确定
季节性与非季节性差分数。
\item 其次利用增强迪基-福勒检验(ADF test, Augmented Dickey Fuller test)判断
序列是否平稳，利用白噪声检验判断序列是否为随机性序列。
\item 最后进行时间序列的定阶。自相关函数 (ACF, AutoCorrelation Function)
和偏自相关函数 (PACF, Partial AutoCorrelation Function) 利用拖尾
和截尾来确定，并应用他们来给时间序列定阶，模型的参数由最大似然 (ML，Maximum
Likelihood) 函数估计。
\end{itemize}

\subsection{Prophet}
Prophet\cite{taylor2018forecasting}是由Facebook于2018年提出的一种时间序
列预测算法框架。其核心部分使用类似于SARIMA的方法进行时间序列预测，可以
学习年、周和日、年的季节性以及假日效应等非线性趋势，最适用于具有强烈季节性影响的时
间序列，可以通过R和Python实现调用。Prophet的预测速度快，不同于SARIMA需要手动
对时间序列进行处理判断以及定阶，Prophet提供了完全自动化的时间序列预测功能，
无需手动操作即可对杂乱的数据进行合理预测，其对异常值、缺失数据和时间序列中的剧烈
变化都具有十分强大的健壮性，并且为用户提供了许多超参数，支持通过交叉验证进行超参数调优。

Prophet的算法模型为：
$$y(t)=g(t)+s(t)+h(t)+\epsilon_{(t)}$$

该公式中g(t) 表示的是趋势分量，代表时间序列数据在非周期性规律中的变化趋势；
s(t) 表示周和日、年的季节性分量；h(t) 表示节假日项，此处和风速预测无关；
$\epsilon_{t}$为剩余项，表示噪声分量，其服从高斯白噪声分布；

\section{基于PCA的降维方法}
\subsection{主成分分析}
主成分分析（PCA，Principal Component Analysis）是一种基于线性变换降低数据集的维度
，从而达到简化数据集目的的方法。其利用正交变换对一系列可能的相关变量的观测值进行线性
变换，从而将其投影为一系列线性不相关的变量特征，并同时保留对彼此差异贡献最大的特征。
这种变换这是通过忽略高维成分并保留低维成分并来实现的。

假设待降为的原始数据有m条，每条数据为n维，组成了n行m列的矩阵X，则PCA的步骤如下：

\begin{itemize}
    \item 首先将X的每一行进行零均值化（减去这一行的均值）。
    \item 求解协方差矩阵$C=\frac{1}{m}XX^\mathsf{T}$，以及其特征值及对应的特征向量。
    \item 将协方差矩阵C的特征向量按对应特征值大小从前到后按行排列成矩阵，取前k行组成新矩阵P。
    \item $Y=PX$即为降维到k维后的数据。
\end{itemize}

\subsection{核主成分分析}
PCA可以很好的解除线性相关，但是对于非线性的高阶相关性，PCA无法处理
\cite{jolliffe2016principal}。核主成分分析（KPCA）是一种基于核函数的主成分
分析方法，其类似于SVR（支持向量回归），通过核函数将非线性相关变换到更高维度，
使其转换为线性相关。因而，KPCA方法可以用于解决非线性的高阶相关性问题，适用于
非平稳非线性关系较强的天气要素数据。

本文核函数使用径向基函数（高斯核函数，RBF核，Radial Basis Function Kernel），
其表达式为：
$$K(\mathbf x,\mathbf y)=e^{-\gamma\|\mathbf x-\mathbf y\|^2}$$

与其他核函数相比，选择RBF核函数的原因是：

\begin{itemize}
\item[1. ] RBF为非线性映射核函数，和风速数据中较多的非线性特征契合，并且线性核
函数也只是RBF的一个特例，因而不使用线性核函数。
\item[2. ] 多项式核函数需要计算内积，容易发生数值溢出的问题。
\item[3. ] Sigmoid 核函数$K(\mathbf x,\mathbf y)=\tanh(b\:\mathbf x^T\mathbf y-c)$
需要确定超参数$b$和$c$，因而不适合用于高阶相关性的自动PCA分解问题。 
\end{itemize}

\section{深度学习模型激活函数}
激活函数将深度学习模型中神经单元的输出映射到一个范围，从而起到控制输出数据值域的作用。
\subsection{sigmoid}
$$sigmoid(x)=\frac{1}{1+e^{-x}}$$
\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/sigmoid.pdf}
    \caption{sigmoid函数图像}
    \label{fig_sigmoid}
\end{figure}
sigmoid函数在$-\infty$上趋近于0，在$+\infty$上趋近于1。

\subsection{tanh}
$$tanh(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}}$$
\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/tanh.pdf}
    \caption{tanh函数图像}
    \label{fig_tanh}
\end{figure}
tanh函数在$-\infty$上趋近于-1，在$+\infty$上趋近于1，且过原点。其实质上是
sigmoid函数的缩放移动版本。

\subsection{GELU}
$$
ReLU=
\left\{\begin{matrix}
    0, & x \leq 0 \\
    x, & x > 0
\end{matrix}\right.
$$

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/relu_gelu.pdf}
    \caption{ReLU和GeLU函数图像}
    \label{fig_relu_gelu}
\end{figure}

尽管整流线性单元（ReLU，Rectified Linear Unit）在x取负值时为0，符合近地面全风速数据不为负
的特点，但是由于ReLU是线性激活函数，而风速数据具有较强的非线性特征，因而用于风速数据效果
不是很理想。

高斯误差线性单元 (GELU，Gaussian Error Linear Unit）是Hendrycks, Dan等人于2016提出的
\cite{hendrycks2016gaussian}一种高性能的神经网络激活函数。GELU 激活函数表达式是
$x\Phi(x)$，其中$\Phi(x)$是标准高斯累积分布函数。GELU 是非线性激活函数，其给输入值进行
高斯加权输入，能带给训练任务更好的精度和拟合效果。

\section{基于RNN的深度学习神经网络模型}
\subsection{循环神经网络}
循环神经网络（RNN，Recurrent Neural Network）是一种深度学习模型。经典的神经网络
\cite{rumelhart1986learning}，多用于图像处理。由于其时序无关，采用了层状传递结构，
模型的内部前一层神经元直接传递给后一层神经元，这样做模型由于无记忆功能，
无法处理时序数据中的历史相关性，因而需要循环层内部传递数据来处理这种时序数据。

\begin{figure}[H]
	\centering
	\subfloat[经典BP神经网络]{
        \includegraphics[width=0.5\textwidth]{figures/ANN.pdf}
    }
	\subfloat[循环神经网络]{
        \includegraphics[width=0.5\textwidth]{figures/RNN.pdf}
    }
    \caption{两种神经网络结构示意图}
    \label{fig_nn}
\end{figure}

假设激活函数为sigmoid，RNN神经网络的每个神经元都是通过输入值和上一层的记忆值同时乘对
应权重并与偏差相加，最终再通过sigmoid激活函数将结果压缩在 0 和 1 之间得出输出。
上述过程得到如下所示公式：
$$h_t=\sigma(Wx_t+Uh_{t-1}+b_z)$$

公式中W代表权重，$b_z$是偏差，$x_t$是t时刻的神经元输入值，$h_{t-1}$是t-1时刻神经
元的记忆输出值，W和U为对应的值的权重，$h_t$是当前神经元的输出值。训练时
对每个神经元采用反向传播(BP)算法，使用训练集中的数据，通过指定学习优化器和损失函数
来迭代计算权重和偏差，从而使误差的最小化。

由循环神经网络的结构和原理也可以看到，由于其在训练反向传播时权重产生的误差都会累加
迭代，因而很容易误差累加数值过大，造成梯度爆炸。同时，由sigmoid激活函数的性质可知，当
值较大时，函数趋于1，并变得平缓，此时进行反向传播会造成整体值过小，造成梯度消失的问题。另外，
循环神经网络的训练过程中每个神经元权重都是直接记忆学习临近时刻的，因而对可能会存在季节
性效应的长期关系的学习不佳。

\subsection{GRU}
上述RNN的三个问题中，梯度爆炸可以采用阈值范围对梯度进行裁剪就可以解决，但是梯度消失和
长期依赖关系的问题则必须要改变模型的结构。LSTM是首先被提出的解决方案
\cite{hochreiter1997long}，GRU则是相对于LSTM更简单且更优异的方案。

GRU是由Cho等人于2014年提出的一种类似于LSTM的神经网络模型\cite{cho2014learning}。
本文之所以选择GRU而非LSTM，是因为相较于LSTM的结构有三个门控单元输入门、遗忘门和输出门，
GRU只有两个，分别为更新门和重置门。并且GRU的单个神经元中并不会保留内部记忆，
因而GRU的参数更少，复杂度更低，收敛速度更快，并且GRU和LSTM所能达到的训练以及预测
效果同样出色，因而对于效果成本比而言GRU要更高\cite{chung2014empirical}。

GRU的工作原理如下：

首先更新门确定有多少过去的信息（来自之前的时间步长）需要传递到未来。计算时间t的更新
门 $z_t$的值，执行计算公式如下：
$$z_t=\sigma(W^{(z)}x_t+U^{(z)}h_{t-1})$$

该公式和标准RNN的计算公式类似。

重置门决定要忘记多少过去的信息，其公式与更新门的公式相同：
$$r_t=\sigma(W^{(r)}x_t+U^{(r)}h_{t-1})$$

然后执行以下计算公式：
$$h^{\prime}_t=tanh(Wx_t+r_t\odot Uh_{t-1})$$

该步骤中重置门和过去的神经元输出进行元素积，确定遗忘掉多少过去的信息
，并和当前的输入值进行整理相加。在此步中，若选择使$r_t$（重置门）的值
接近0，则可以遗忘掉过去的大部分信息。

最后一步，确定当前步骤需要记忆的信息：
$$h_t=z_t\odot r_t+(1-z_t)\odot h^{\prime}_t$$

该模型可以选择使$z_t$（更新门）的值接近1，从而并保留大部分过去的信息
。并且由于此时$1-z_t$接近0，因而将忽略对当前内容的记忆。

从上述推导步骤可以得出GRU模型解决长期记忆问题的方法。同时接近1和接近0的同时出现也
解决了梯度消失的问题。

从上述推导过程还可以得出，如果选择将重置门设置为1，更新门设置为0，那么GRU将
变为标准的 RNN 模型。

\section{深度学习模型优化器}
本部分内容参考了Ruder, Sebastian的梯度下降优化算法综述\cite{ruder2016overview}。
\subsection{SGD}
随机梯度下降（SGD，Stochastic Gradient Descent）是深度学习神经网络的训练基础算法，
它是一种比较简单的梯度下降算法。假设目标神经网络函数为$J(\theta)$，神经网络的参数值
为$\theta$。则SGD根据固定的学习率η，通过在目标函数梯度的相反方向上$\nabla_\theta J( \theta)$
更新参数$\theta$来搜寻神经网络的参数，使得目标神经网络达到局部最优点。

SGD的更新公式为：
$$\theta = \theta - \eta\nabla_\theta J( \theta)$$

\subsection{Momentum}
Momentum是Qian, Ning研究出的\cite{qian1999momentum}一种有助于在梯度下降的
方向加速 SGD 并抑制SGD振荡的方法。它通过添加动量项比值γ，将过去时间步的更新向
量到添加到当前的更新向量，来实现这一目的。

Momentum的更新公式为：
$$
\begin{matrix}
v_t = \gamma v_{t-1} + \eta \nabla_\theta J( \theta)\\
\theta = \theta - v_t
\end{matrix}
$$

\subsection{NAG}
涅斯捷罗夫加速梯度下降（NAG，Nesterov Accelerated Gradient）\cite{nesterov1983method}
基于Momentum，通过$\theta - \gamma v_{t-1}$项使其能够预知未来的更新方向，
从而使得更新更加稳定而不至于一直遵循梯度更新的惯性。这种预期性的更新可以防止
梯度更新得太快，从而提高响应能力。NAG显著提高了 RNN 在许多训练任务中的性能
\cite{bengio2013advances}。

NAG的更新公式为：
$$
\begin{matrix}
v_t = \gamma v_{t-1} + \eta \nabla_\theta J( \theta - \gamma v_{t-1} )\\ 
\theta = \theta - v_t 
\end{matrix}
$$

\subsection{Adam}
Adam\cite{kingma2014adam}是一种基于 RMSProp 的优化器，它能够自动化调整学习率，
对与频繁出现的特征相关的参数执行较小的更新（低学习率），对与不常见特征相关的参数
执行较大的更新（高学习率），同时还能适应稀疏数据，克服学习率急剧下降的问题。
其本质上为带Momentum动量项的RMSProp。

\subsection{Nadam}
Nadam\cite{dozat2016incorporating}向Adam优化器中融合了 NAG 的思想，向Adam中添加
了Nesterov 动量，从而使其获得了NAG的能够预知未来的更新方向的优点，提高其在 RNN 训练
任务中的性能，最终期望使用Nadam取得比Adam更好的效果。

\section{深度学习模型损失函数}
\subsection{均方损失函数（MSE）}
$$MSE=\sum_{t=1}^{N}\left(\hat{y}\left(t\right)-y\left(t\right)\right)^2$$

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/mse.pdf}
    \caption{mse函数图像}
    \label{fig_mse}
\end{figure}

MSE 是平方损失函数，如图\label{fig_mse}所示，其光滑连续且可导，并且随着误差的减小，
梯度也在减小，从而利于函数的收敛。因而MSE适合于对其使用梯度下降算法。但是，由于MSE
的梯度会随着误差的增大而增大，如果样本中存在较多的异常点，MSE 会给这些异常点平方倍
的权重，从而牺牲正常点的回归预测效果。

\subsection{平均绝对损失函数（MAE）}
$$MAE=\sum_{t=1}^{N}\left|\hat{y}\left(t\right)-y\left(t\right)\right|$$

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/mae.pdf}
    \caption{mae函数图像}
    \label{fig_mse}
\end{figure}

如图\label{fig_mae}所示，MAE 是连续且在非零点处可导的，但是由于其是线性损失函数，
梯度始终保持不变。因而在优化器学习率保持不变的情况下，MAE不利于函数的收敛。但是，
由于MAE将异常点和正常点同等看待，因而克服了MSE的缺点。

\subsection{Huber损失函数}
$$
Huber=
\left\{\begin{matrix}
    \frac{1}{2}(y\left(t\right) - \hat{y}\left(t\right))^{2}, & \left | (y - \hat{y})  \right | < \delta\\
    ((y\left(t\right) - \hat{y}\left(t\right)) - \frac1 2 \delta)\delta, & \left | (y - \hat{y})  \right | \geq \delta
\end{matrix}\right.
$$

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/huber.pdf}
    \caption{huber函数图像}
    \label{fig_huber}
\end{figure}

Huber 损失函数\cite{huber1992robust}包含了一个超参数 δ。当预测偏差小于 δ 时，
它采用MSE变换形式的平方损失函数；当预测偏差大于等于 δ 时，采用MAE变换形式的线性损失函数，
如图\label{fig_huber}所示。
因而，Huber同时综合了MSE和MAE的优点并同时客服了他们的缺点。

Huber 光滑连续且可导，当误差达到临界点δ时随着误差的减小，梯度也在减小，对于异常点
的误差超出临界点δ时，不会给这些异常点很大的的权重，从而同时达到一个很好的收敛和预测
效果。

\chapter{模型的建立和评估}
\section{模型评价指标公式}
下述指标公式使用scikit-learn自带的方法实现，并和25\%准确率（预测值和真实值实际偏差
数值在25\%以内的比值）封装为print\_metrics函数调用，相关代码见附录部分A.4。

\subsection{均方误差（MSE）}
$$MSE=\frac{1}{N}\sum_{t=1}^{N}\left(\hat{y}\left(t\right)-y\left(t\right)\right)^2$$

\subsection{平均绝对误差（MAE）}
$$MAE=\frac{1}{N}\sum_{t=1}^{N}\left|\hat{y}\left(t\right)-y\left(t\right)\right|$$

\subsection{平均绝对误差百分比（MAPE）}
$$MAPE=\frac{1}{N}\sum_{t=1}^{N}\left|\frac{\hat{y}\left(t\right)-y\left(t\right)}{y\left(t\right)}\right|$$

\subsection{均方根误差（RMSE）}
$$RMSE=\sqrt{\frac{1}{N}\sum_{t=1}^{N}\left(\hat{y}\left(t\right)-y\left(t\right)\right)^2}$$

上述四种误差指标都为越小模型的精度越高。

\subsection{决定系数（$R^2$）}
$$R^2=1-\frac{\sum_{t=1}^{N}(\hat{y}\left(t\right)-y\left(t\right))^2}{\sum_{t=1}^{N}(\bar{y}\left(t\right)-y\left(t\right))^2}$$

决定系数（$R^2$）取值范围为$(-\infty, 1]$，越接近1代表模型的准确度越好。

\section{七种特征数据的ICEEMDAN分解}
下述ICEEMDAN分解以及时域转频域和图片生成代码请见附录部分A.5。

这里使用python的pyEMD库实现ICCEMDAN分解\footnote{尽管pyEMD库中调用方法和类名为CEEMDAN，
但根据官方文档，其内部实现时是采用的改进的CEEMDAN，即ICEEMDAN发表论文中所述算法。}，并使用
numpy库相关方法进行傅里叶变换生成幅频，最终使用Matplotlib进行可视化作图。

图中第一行为原始数据，最后一行为ICEEMDAN分解后得到的残差，中间的行为ICEEMDAN分解后得到的
本征模函数（IMF）分量。其中，每行左侧为原始得到的时域数据，横坐标范围为[0,5839]，单位为三小时（3hr）。
右侧为经过傅里叶变换后得到的频域数据，横坐标范围为[0,2919]，单位为赫兹（HZ）。

\subsection{地面向下长波辐射}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/lrad.pdf}
    \caption{地面向下长波辐射的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_lrad}
\end{figure}

从图\ref{fig_lrad}中可以看到，原始信号中高频噪声含量较高。ICEEMDAN将地面向下长波辐射
的原始时间序列分解为10个本征模函数（IMF）分量，分解效果显著。由幅频可以看出，高频噪声
主要集中在IMF1分量和IMF2分量中，集中于500HZ-3000HZ处。

\subsection{地面降水率}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/prec.pdf}
    \caption{地面降水率的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_prec}
\end{figure}

从图\ref{fig_prec}中可以看到，原始信号中高频噪声含量也较高。ICEEMDAN将地面降水率
的原始时间序列分解为14个本征模函数（IMF）分量，分解效果较好。由幅频可以看出，高频噪声
主要集中在IMF1、IMF2分量和IMF3分量中，集中于200HZ-3000HZ处。

\subsection{近地面气压}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/pres.pdf}
    \caption{近地面气压的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_pres}
\end{figure}

从图\ref{fig_pres}中可以看到，原始信号中高频噪声含量同样较高。ICEEMDAN将近地面气压
的原始时间序列分解为9个本征模函数（IMF）分量，分解效果显著。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于500HZ-2300HZ处。

\subsection{近地面空气比湿}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/shum.pdf}
    \caption{近地面空气比湿的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_shum}
\end{figure}

从图\ref{fig_shum}中可以看到，原始信号中高频噪声含量也较高。ICEEMDAN将近地面空气比湿
的原始时间序列分解为10个本征模函数（IMF）分量，分解效果较好。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于750HZ-3000HZ处。

\subsection{地面向下短波辐射}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/srad.pdf}
    \caption{地面向下短波辐射的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_srad}
\end{figure}

从图\ref{fig_srad}中可以看到，原始信号中高频噪声含量也较高。ICEEMDAN将地面向下短波辐射
的原始时间序列分解为10个本征模函数（IMF）分量，分解效果十分显著。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于750HZ-2200HZ处。

\subsection{近地面气温}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/temp.pdf}
    \caption{近地面气温的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_temp}
\end{figure}

从图\ref{fig_temp}中可以看到，原始信号中高频噪声含量同样较高。ICEEMDAN将近地面气温
的原始时间序列分解为8个本征模函数（IMF）分量，分解效果显著。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于500HZ-2200HZ处。

\subsection{近地面全风速}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/wind.pdf}
    \caption{近地面全风速的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_wind}
\end{figure}

从图\ref{fig_wind}中可以看到，原始信号中高频噪声含量也较高。ICEEMDAN将近地面全风速
的原始时间序列分解为11个本征模函数（IMF）分量，分解效果显著。由幅频可以看出，高频噪声
主要集中在IMF1、IMF2和IMF3分量中，集中于500HZ-3000HZ处。

\section{仅使用风速历史时间序列数据的Prophet模型}
\subsection{搜寻最优超参数}
直接将原始风速时间序列数据作为输入，首先使用Prophet自带的实现方法，对数据进行交叉验证
以评估5天的预测性能，为超参数调优提供依据。首先对训练集和验证集进行六四分，共730天的
数据选择前438天（3504条数据）作为初始训练数据。对于后290天（2320条数据），每隔5天对
未来5天的情况进行一次预测，共计验证58次，搜寻Prophet的最优超参数，从而使得平均绝对
误差百分比（MAPE）值最小化。使用的代码见附录部分A.6。最终得到对于风速序列的最优参数
如下表所示：

\begin{table}[H]
    \centering
    \caption{风速历史时间序列数据Prophet模型的最优超参数}
    \begin{tabular}{cc}
    \toprule
    超参数名 & 值 \\
    \midrule
    changepoint\_prior\_scale & 1.0 \\
    seasonality\_prior\_scale & 0.1 \\
    seasonality\_mode & additive \\
    changepoint\_range & 1 \\
    \bottomrule
    \end{tabular}
    \label{prophet_param}
\end{table}

\subsection{建模结果}

将数据集前5800条（725天）作为训练集，后40条（5天）作为测试集。最终将上述超参数带
入Prophet模型中建模，对5800条时序数据输入Prophet模型进行训练。代码部分见附录部分A.7。

模型预测结果和实际值之间的比较：

\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/prophet_wind.pdf}
    \caption{仅使用风速历史数据Prophet模型实际值（黑色散点）和预测值（蓝色曲线）之间的对比}
    \label{fig_prophet_wind}
\end{figure}

最终模型的评价指标情况：

\begin{table}[H]
    \centering
    \caption{仅使用风速历史时间序列数据Prophet模型的评价指标值}
    \begin{tabular}{cc}
    \toprule
    MAPE & 0.811048306594047 \\
    MAE & 1.669410108638486 \\
    MSE & 4.676397471905323 \\
    RMSE & 2.1624979703817813 \\
    $R^2$ & 0.1546359378992639 \\
    25\% 准确度 & 0.35551724137931034 \\
    \bottomrule
    \end{tabular}
    \label{wind_prophet_result}
\end{table}

\section{仅使用风速历史时间序列数据的ICEEDMAN-Prophet模型}
将对风速历史时间序列数据ICEEDMAN分解所得的所有IMF分量以及残差共计12项，每项5800条数据
作为Prophet输入，对每项分别进行Prophet模型的预测，最终将12个Prophet模型所得的结果相加，计算模型的指
标值。代码部分见附录部分A.8。

\begin{table}[H]
    \centering
    \caption{仅使用风速历史时间序列数据ICEEDMAN-Prophet模型的评价指标值}
    \begin{tabular}{cc}
    \toprule
    MAPE & 0.809527314909222 \\
    MAE & 1.6655091375859066 \\
    MSE & 4.656702225688189 \\
    RMSE & 2.157939347082811 \\
    $R^2$ & 0.15819629679651703 \\
    25\% 准确度 & 0.3618965517241379 \\
    \bottomrule
    \end{tabular}
    \label{wind_iceemdan_prophet_result}
\end{table}

同时还尝试了对残差以及部分高频分量预测结果直接去除进行尝试，经试验在所有使用的模型指标中
都会进一步加大模型的误差，并不会产生更好的效果。

\section{仅使用风速历史时间序列数据的ICEEDMAN-Prophet-GRU模型}
\subsection{模型介绍}
将上两种模型得到的仅使用风速历史时间序列数据Prophet相关共计13个模型输出的结果以及统计分析预
测得出的趋势分量、累加式季节性分量、日分量、年分量以及上述分量所对应的预测最大边界和最
小边界共计15个特征进行整合，得到一个（5840，195）的矩阵，再次将其前5800条（725天）作为
训练集，后40条（5天）作为测试集。对测试集首先进行数据标准化缩放，再通过使用RBF核函数的核
主成分分析（KPCA），将训练集
升维至（5800，5799）输入进入GRU模型，从而得到最终的预测结果。代码部分见附录部分A.9。

使用的GRU模型网络结构如图\ref{fig_gru}所示：

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/gru_model_plot.pdf}
    \caption{本文使用的GRU模型网络结构图}
    \label{fig_gru}
\end{figure}

该模型四层之间使用序贯模型的形式进行连接。第一层为模型的输入层，每次输入一个（1，5799）的
向量，代表经过Prophet处理的的初步预测值。第二层为一个使用标准GRU模型（即激活函数为sigmoid，
循环激活函数为tanh）的隐藏层，其一共有1024个GRU单元，输出为（1，1024）的向量，可训练参数
共计20966400个。第三层为一个将激活函数和循环激活函数都改为gelu的GRU模型，其共计512个GRU单
元，输出为（1，512）的向量，可训练参数为2362368个。第四层为输出层，将前一层的输出值通过全连
接的方式，得到（1，1）的向量，为最终预测值，可训练参数513个。整个模型可训练参数
共计23329281个。

\subsection{建模结果}
使用Tensorflow Keras，选择训练100个epoch，批大小（Batch Size）为默认32，训练过程中验证集
自动按照0.01的占比划分，且设置回调函数自动保存训练过程中得到的损失最小的模型。损失函数为
Huber，模型优化器为Nadam，设定学习率为0.001。最终100个epoch结束时得到的最优模型的Huber损失
值为0.0122。

训练过程中Huber损失函数的变化情况：

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/wind_prophet_gru_training_loss.pdf}
    \caption{仅使用风速历史的ICCEMDAN-Prophet-GRU模型训练损失变化}
    \label{fig_wind_prophet_gru_training_loss}
\end{figure}

最终模型在训练集中的拟合情况：

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/wind_prophet_gru_predict_train.pdf}
    \caption{仅使用风速历史的ICCEMDAN-Prophet-GRU模型训练集拟合}
    \label{fig_wind_prophet_gru_predict_train}
\end{figure}

最终模型的评价指标数值：

\begin{table}[H]
    \centering
    \caption{仅使用风速历史的ICCEMDAN-Prophet-GRU模型的评价指标值}
    \begin{tabular}{cc}
    \toprule
    MAPE & 0.057870873111315564 \\
    MAE & 0.15543329288182148 \\
    MSE & 0.11384164320704779 \\
    RMSE & 0.33740427265677564 \\
    $R^2$ & 0.9794227551357394 \\
    25\% 准确度 & 0.9806896551724138 \\
    \bottomrule
    \end{tabular}
    \label{wind_prophet_gru_result}
\end{table}

\section{多特征ICEEDMAN-Prophet-GRU模型}

和上一种模型类似，将近地面气温、近地面气压、近地面空气比湿、地面向下短波辐射、地面向下长
波辐射、地面降水率，和近地面全风速7种气象要素的原始历史数据以及ICCEMDAN分解得到的每个IMF
分量以及残差分别输入进Prophet模型进行预测，最终得到的86个模型，每个模型的（5840，
15）形状的输出矩阵和上一个模型进行同样的整理，得到形状为（5840，1290）的矩阵，再对数据和
上一个模型进行同样的处理，得到GRU的输入矩阵（5800，5799），GRU的各种参数以及训练方法
和上一个模型的步骤一样。最终100个epoch结束时得到的最优模型的Huber损失为0.0081。
代码部分见附录部分A.10。

训练过程中Huber损失函数的变化情况：

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/all_prophet_gru_training_loss.pdf}
    \caption{多特征ICCEMDAN-Prophet-GRU模型训练损失变化}
    \label{fig_all_prophet_gru_training_loss}
\end{figure}

最终模型在训练集中的拟合情况：

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/all_prophet_gru_predict_train.pdf}
    \caption{多特征ICCEMDAN-Prophet-GRU模型训练集拟合}
    \label{fig_all_prophet_gru_predict_train}
\end{figure}

最终模型的评价指标数值：

\begin{table}[H]
    \centering
    \caption{多特征ICCEMDAN-Prophet-GRU模型的评价指标值}
    \begin{tabular}{cc}
    \toprule
    MAPE & 0.04486806982673257 \\
    MAE & 0.12356680479810452 \\
    MSE & 0.07946772036320189 \\
    RMSE & 0.2819001957487825 \\
    $R^2$ & 0.9856359527616432 \\
    25\% 准确度 & 0.9853448275862069 \\
    \bottomrule
    \end{tabular}
    \label{all_prophet_gru_result}
\end{table}

\section{上述四种模型的对比评估}

可以看到，仅使用风速历史时间序列数据的Prophet模型MAPE值为81\%左右，准确率十分地低。通过
ICCEMDAN分解处理后，模型的各项指标都相较于仅使用风速历史时间序列数据的Prophet模型的指标
有了提高，但是提高得不显著。

仅使用风速历史时间序列数据的ICCEMDAN-Prophet模型在通过GRU模型进行处理之后，
模型的各项指标都得到了大幅度的显著提高，MAPE达到了个位数。但是其收敛速度
没有多特征模型的快，因而最终结果体现了多特征ICEEDMAN-Prophet-GRU模型的优越性。

\chapter{总结与展望}

本文综合使用目前最新的科研成果，基于ICEEMDAN进行了多气象要素的特征分解，而不仅仅是使用
风速的历史时间序列。并且采用Prophet与 GRU 的组合模型，对相关模型进行优化，突破模型的刻板
传统，使用了RBF核PCA升维、GELU以及Nadam优化器和Huber损失函数，并将这些应用到了短期风速预测领
域，并通过选择甘肃酒泉的一个真实风力发电厂附近进行短期风速的预测，最终预测结果显示了该模型
的优势和极大的实用价值。

当然，因为论文时间紧迫，展望未来，本次论文写作过程也存在着许多遗憾的点：

\begin{itemize}
\item[1.] 本次建模过程只选择了两年跨度的时间序列数据，没有将更大尺度的数据进行处理，对于大尺度数据而言
模型应该能进一步取得更好的效果。
\item[2.] 由于Prophet搜寻最优超参数所耗费时间过长，本文只对风速原始时间序列数据这一个模型进行了搜索最
优超参数的过程，因为对于一个模型的超参数搜寻时间在作者电脑中运行完成大概就要花上8个小时的时
间，对于其他特征时间序列以及他们分解出的ICEEMDAN的IMF分量以及残差时间序列数据共计85个模型，
子模型太多，所需时间成本太大。所以本文则直接沿用了风速原始时间序列数据的最优超参数。如果对
86个Prophet子模型每个都加以优化，预计会产生更好的效果。
\item[3.] 本文只选择了甘肃酒泉的一个真实风力发电厂附近的地点进行短期风速的预测，当然本文作者坚信在其他
地点本模型也会产生很好的效果，后续有待验证这一点。
\end{itemize}

%论文后部
\backmatter


%=======%
%引入参考文献文件
%=======%
\bibdatabase{bib/database}%bib文件名称 仅修改bib/ 后部分
\printbib
% \nocite{*} %显示数据库中有的，但是正文没有引用的文献


\Appendix

\section{数据集制作代码}

\begin{lstlisting}[language = python]
from netCDF4 import Dataset
import datetime

# 甘肃中电酒泉第四风力发电有限公司
lat_index = 256
lon_index = 269
variable_list = ["lrad", "prec", "pres", "shum",
                    "srad", "temp", "wind"]
with open('data.csv', 'w') as f:
    f.write("ds")
    for variable in variable_list:
        f.write(',' + variable)
    f.write('\n')
    for year in range(2017, 2019):
        for month in range(1, 13):
            dataset = []
            time_data = []
            for name in variable_list:
                data = Dataset("data/" + name + 
                                "_ITPCAS-CMFD_V0106_B-01_03hr_010deg_"
                                + str(year) + str(month).zfill(2) +
                                ".nc")
                dataset.append(data.variables[name][:])
                time_data = data.variables['time'][:]

            for index in range(len(time_data)):
                f.write(datetime.datetime.utcfromtimestamp(
                    (time_data[index]-613608)*3600).strftime(
                        "%Y-%m-%d %H:%M:%S"))
                for data in dataset:
                    f.write(',' + str(
                            data[index][lat_index][lon_index]))
                f.write('\n')
\end{lstlisting}

\section{表\ref{analysis} 中的数据源制作代码}

\begin{lstlisting}[language = python]
import pandas as pd
data = pd.read_csv('data.csv')
stat = data.describe()
stat.loc['range'] = stat.loc['max']-stat.loc['min']
stat.loc['dis'] = stat.loc['75%']-stat.loc['25%']
stat.loc['var'] = stat.loc['std']/stat.loc['mean']
stat.loc['mad'] = data.mad()
stat.loc['skew'] = data.skew()
stat.loc['kurt'] = data.kurt()
print(stat)
\end{lstlisting}

\section{表\ref{relativity-analysis} 中的数据源制作代码}

\begin{lstlisting}[language = python]
from scipy import stats
for item in ['lrad', 'prec', 'pres', 'shum', 'srad', 'temp']:
    print(stats.spearmanr(
          data[[item]].to_numpy().ravel(),
          data[['wind']].to_numpy().ravel()))
\end{lstlisting}

\section{模型评价指标实现代码}

\begin{lstlisting}[language = python]
from sklearn import metrics
def print_metrics(pred, y_vals):
    print('mape: ', metrics.mean_absolute_percentage_error(y_vals, pred))
    print('mae: ', metrics.mean_absolute_error(y_vals, pred))
    print('mse: ', metrics.mean_squared_error(y_vals, pred))
    print('rmse: ', np.sqrt(metrics.mean_squared_error(y_vals, pred)))
    print('r2: ', metrics.r2_score(y_vals, pred))
    count = 0
    y_error = pred.flatten() - y_vals.flatten()
    y_error = np.array([abs(e) for e in y_error]).flatten()
    for i in range(len(y_error)):
        if(y_error[i] < 0.25 * y_vals[i]):
            count += 1
    print('25% 准确度: ', count / len(pred))
\end{lstlisting}

\section{图\ref{fig_lrad}-图\ref{fig_wind} 制作代码以及保存ICEEMDAN分解数据至csv文件}

\begin{lstlisting}[language = python]
import matplotlib.pyplot as plt
%matplotlib notebook
plt.rcParams['font.size']=64
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus'] = False

import numpy as np
from PyEMD import CEEMDAN
def draw_spectrum_map(x):
    xf = np.fft.fft(x)
    xf_abs = np.fft.fftshift(abs(xf))[len(x)//2:]
    plt.plot(xf_abs)

IImfs=[]
def ceemdan_decompose_res(data, trials=100, epsilon=0.005, noise_scale=1, noise_kind="normal", range_thr=0.01, total_power_thr=0.05):
    ceemdan = CEEMDAN(parallel=True, processes=8, trials=trials, epsilon=epsilon, noise_scale=noise_scale, noise_kind=noise_kind, range_thr=range_thr, total_power_thr=total_power_thr)
    ceemdan.ceemdan(data)
    imfs, res = ceemdan.get_imfs_and_residue()
    plt.subplots_adjust(hspace=0.5)
    plt.subplot(imfs.shape[0]+3, 2, 1)
    plt.plot(data,'r')
    plt.title(u"时域")
    plt.ylabel(u"原始数据")
    plt.subplot(imfs.shape[0]+3, 2, 2)
    draw_spectrum_map(data)
    plt.title(u"频域")
    for i in range(imfs.shape[0]):
        plt.subplot(imfs.shape[0]+3, 2, 2*i+3)
        plt.plot(imfs[i], 'g')
        plt.ylabel("IMF %i" %(i+1))
        plt.locator_params(axis='x', nbins=10)
        plt.subplot(imfs.shape[0]+3, 2, 2*i+4)
        draw_spectrum_map(imfs[i])
        IImfs.append(imfs[i])
    plt.subplot(imfs.shape[0]+3, 2, 2*imfs.shape[0]+3)
    plt.plot(res,'g')
    plt.ylabel(u"残差")
    plt.subplot(imfs.shape[0]+3, 2, 2*imfs.shape[0]+4)
    draw_spectrum_map(res)
    return res
count = 0
for name in ["lrad", "prec", "pres", "shum", "srad", "temp", "wind"]:
    pic = plt.figure(figsize=(64,64))
    input_data = data[name].to_numpy().ravel()
    ceemdan_decompose_res(input_data)
    with open(name + '.csv', 'w') as f:
        f.write("ds")
        for i in range(1, len(IImfs)-count+1):
            f.write(',IMF' + str(i))
        f.write('\n')
        for n in range(len(input_data)):
            f.write(data['ds'][n])
            for index in range(count, len(IImfs)):
                f.write(',' + str(IImfs[index][n]))
            f.write('\n')
    count=len(IImfs)
    pic.savefig(name + ".pdf")
\end{lstlisting}

\section{仅使用风速历史时间序列数据的Prophet模型的参数交叉验证调优}

\begin{lstlisting}[language = python]
import itertools
from prophet import Prophet
from prophet.diagnostics import cross_validation
from prophet.diagnostics import performance_metrics
param_grid = {  
    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5, 1.0, 10.0, 100.0, 1000.0, 10000.0],
    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],
    'seasonality_mode': ['additive', 'multiplicative'],
    'changepoint_range': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
}

all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]
mapes = []

df = pd.DataFrame(data['ds'])
df['y'] = data['wind']

for params in all_params:
    m = Prophet(yearly_seasonality=True, **params).fit(df)
    df_cv = cross_validation(m, initial='438 days', period='5 days', horizon = '5 days', parallel="processes")
    df_p = performance_metrics(df_cv, rolling_window=1)
    mapes.append(df_p['mape'].values[0])

tuning_results = pd.DataFrame(all_params)
tuning_results['mape'] = mapes

best_params = all_params[np.argmin(mapes)]
print(best_params)
\end{lstlisting}

\section{仅使用风速历史时间序列数据的Prophet模型实现代码}

\begin{lstlisting}[language = python]
from prophet import Prophet
split_line=5800
df = pd.DataFrame(data['ds'][:split_line])
df['y'] = data['wind'][:split_line]
m = Prophet(changepoint_prior_scale=1.0, seasonality_prior_scale=0.1, seasonality_mode='additive', changepoint_range=1, yearly_seasonality=True)
m.fit(df)
future = m.make_future_dataframe(periods=len(data['ds'])-split_line, freq='3H')
forecast = m.predict(future)
fig = m.plot(forecast)
fig.savefig("prophet_wind.pdf")

print_metrics(forecast['yhat'][:split_line].to_numpy(), data['wind'][:split_line].to_numpy())
\end{lstlisting}

\section{仅使用风速历史时间序列数据的ICEEDMAN-Prophet模型实现代码}

\begin{lstlisting}[language = python]
wind_iceemdan = pd.read_csv('wind.csv')
forecasted=[]
for index in wind_iceemdan.columns:
    if index == 'ds' or index == 'orig':
        continue
    temp_df = pd.DataFrame(wind_iceemdan['ds'][:split_line])
    temp_df['y'] = wind_iceemdan[index][:split_line]
    m = Prophet(changepoint_prior_scale=1.0, seasonality_prior_scale=0.1, seasonality_mode='additive', changepoint_range=1, yearly_seasonality=True)
    m.fit(temp_df)
    future = m.make_future_dataframe(periods=len(wind_iceemdan['ds'])-split_line, freq='3H')
    forecast = m.predict(future)
    forecasted.append(forecast['yhat'].to_numpy().ravel())
import copy
result = copy.deepcopy(forecasted[0])
for i in range(1, len(forecasted)):
    result += forecasted[i]

print_metrics(result[:split_line], data['wind'][:split_line].to_numpy())
\end{lstlisting}

\section{仅使用风速历史时间序列数据的ICEEDMAN-Prophet-GRU模型实现代码}

\begin{lstlisting}[language = python]
from prophet import Prophet
import os
split_line=5800
filename='prophet_wind_ceemdan.npy'
if os.path.isfile(filename):
    X=np.load(filename)
else:
    X=np.empty((data.shape[0],0))
    wind_iceemdan = pd.read_csv('wind.csv')
    features = ['trend', 'yhat_lower', 'yhat_upper', 'trend_lower', 'trend_upper', 'additive_terms',
                'additive_terms_lower', 'additive_terms_upper', 'daily', 'daily_lower', 'daily_upper',
                'yearly', 'yearly_lower', 'yearly_upper', 'yhat']
    for index in wind_iceemdan.columns:
        if index == 'ds':
            continue
        temp_df = pd.DataFrame(wind_iceemdan['ds'][:split_line])
        temp_df['y'] = wind_iceemdan[index][:split_line]
        m = Prophet(changepoint_prior_scale=1.0, seasonality_prior_scale=0.1, seasonality_mode='additive', changepoint_range=1, yearly_seasonality=True)
        m.fit(temp_df)
        future = m.make_future_dataframe(periods=len(wind_iceemdan['ds'])-split_line, freq='3H')
        forecast = m.predict(future)
        X=np.append(X, forecast[features].to_numpy(), axis=1)
    np.save(filename, X)

print(X.shape)

shift = 1
X_train = np.array(X[:split_line])
X_test = np.array(X[split_line:])
y = data[["wind"]][shift:]
y_train = np.array(y[:split_line])
y_test = np.array(y[split_line:])

from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)
from sklearn.decomposition import KernelPCA
pca = KernelPCA(kernel='rbf')

X_train = pca.fit_transform(X_train)
X_test = pca.transform(X_test)
print(X_train.shape)

X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))
X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))

from tensorflow import keras
modelname='wind_prophet_gru'
if os.path.isdir(modelname):
    model = keras.models.load(modelname)
else:
    model = keras.models.Sequential()
    model.add(keras.layers.GRU(1024,input_shape = (1, X_train.shape[2]),return_sequences = True))
    model.add(keras.layers.GRU(512,activation = 'gelu', recurrent_activation = 'gelu',return_sequences = True))
    model.add(keras.layers.Dense(1))
    es_callback = keras.callbacks.EarlyStopping(patience = 20, restore_best_weights = True, monitor="loss")
    model.compile(loss = keras.losses.Huber(), optimizer = keras.optimizers.Nadam(0.001))
    model.summary()
    keras.utils.plot_model(model, to_file=modelname+'model_plot.pdf', show_shapes=True, show_layer_names=True)
    history=model.fit(X_train, y_train, validation_split = 0.01, epochs = 100, verbose = 1,
                      shuffle = True, callbacks = [es_callback])
    import matplotlib.pyplot as plt
    %matplotlib notebook
    plt.rcParams['font.size']=64
    plt.rcParams['font.sans-serif']=['SimHei']
    plt.rcParams['axes.unicode_minus'] = False
    pic = plt.figure(figsize=(32,32))
    plt.plot(history.history['loss'])
    plt.title(u'仅使用风速历史的ICEEDMAN-Prophet-GRU模型训练损失变化')
    plt.xlabel(u'Epoch')
    plt.ylabel(u'损失')
    pic.savefig(modelname + "_training_loss.pdf")
    model.save(modelname)

predicted = model.predict(X_train).flatten()
predicted[predicted < 0] = 0

predictions = model.predict(X_test).flatten()
predictions[predictions < 0] = 0

print_metrics(predicted, y_train)

generated = pd.DataFrame(data['ds'])[:-shift]
generated['y_pred'] = np.append(predicted, predictions)[:-shift]
generated['y_real'] = np.array(y)
generated.to_csv(modelname + ".csv")

import matplotlib.pyplot as plt
%matplotlib notebook
plt.rcParams['font.size']=64
plt.rcParams['font.sans-serif']=['SimHei']
plt.rcParams['axes.unicode_minus'] = False
fore_line=4100
end_line=4200
pic = plt.figure(figsize=(32,32))
plt.plot(y_train[fore_line:end_line],'g',predicted[fore_line:end_line],'r')
plt.title('仅使用风速历史的ICEEDMAN-Prophet-GRU模型训练集拟合')
plt.plot(y_train[fore_line:end_line],'g',label=u'真实值')
plt.plot(predicted[fore_line:end_line],'r',label=u'预测值')
plt.xlabel(u'时间（3小时）')
plt.ylabel(u'近地面全风速（m/s）')
plt.legend()
pic.savefig(modelname + "_predict_train.pdf")
\end{lstlisting}

\section{多特征ICEEDMAN-Prophet-GRU模型实现代码}

\begin{lstlisting}[language = python]
# 使用下述2-22行代码替换上部分4-23行代码
filename='prophet_all_ceemdan.npy'
if os.path.isfile(filename):
    X=np.load(filename)
else:
    X=np.empty((data.shape[0],0))
    for name in ["lrad", "prec", "pres", "shum", "srad", "temp", "wind"]:
        all_iceemdan = pd.read_csv(name + '.csv')
        features = ['trend', 'yhat_lower', 'yhat_upper', 'trend_lower', 'trend_upper', 'additive_terms',
                    'additive_terms_lower', 'additive_terms_upper', 'daily', 'daily_lower', 'daily_upper',
                    'yearly', 'yearly_lower', 'yearly_upper', 'yhat']
        for index in all_iceemdan.columns:
            if index == 'ds':
                continue
            temp_df = pd.DataFrame(all_iceemdan['ds'][:split_line])
            temp_df['y'] = all_iceemdan[index][:split_line]
            m = Prophet(changepoint_prior_scale=1.0, seasonality_prior_scale=0.1, seasonality_mode='additive', changepoint_range=1, yearly_seasonality=True)
            m.fit(temp_df)
            future = m.make_future_dataframe(periods=len(all_iceemdan['ds'])-split_line, freq='3H')
            forecast = m.predict(future)
            X=np.append(X, forecast[features].to_numpy(), axis=1)
    np.save(filename, X)

# 使用下述1行代码替换上部分第49行代码
modelname='all_prophet_gru'

# 使用下述1行代码替换上部分第70行代码
plt.title(u'多特征ICEEDMAN-Prophet-GRU模型训练损失变化')

# 使用下述1行代码替换上部分第98行代码
plt.title('多特征ICEEDMAN-Prophet-GRU模型训练集拟合')
\end{lstlisting}

\section{文中使用的函数图像绘制代码}

\begin{lstlisting}[language = python]
import matplotlib.pyplot as plt
import numpy as np
right=4
left=-right
x = np.arange(left, right, 0.01)
def initialize_plot():
    plt.xlim(left,right)
    plt.ylim(left,right)
    ax = plt.gca()
    ax.spines['right'].set_color('none')
    ax.spines['top'].set_color('none')
    ax.xaxis.set_ticks_position('bottom')
    ax.yaxis.set_ticks_position('left')
    ax.spines['bottom'].set_position(('data',0))
    ax.spines['left'].set_position(('data',0))

name='sigmoid'
fig = plt.figure(figsize=(6,6))
initialize_plot()
y = 1.0/(1.0+np.exp(-x))
plt.plot(x, y, label = name)
plt.legend()
fig.savefig(name + ".pdf")

name='tanh'
fig = plt.figure(figsize=(6,6))
initialize_plot()
y = (np.exp(x) - np.exp(-x)) / (np.exp(x) + np.exp(-x))
plt.plot(x, y, label = name)
plt.legend()
fig.savefig(name + ".pdf")

fig = plt.figure(figsize=(6,6))
initialize_plot()
ReLU = np.where(x < 0, 0, x)
GeLU = 0.5*x*(1+ np.tanh(np.sqrt(2/np.pi)*(x+0.044715*np.power(x,3))))
plt.plot(x, ReLU, label = 'ReLU')
plt.plot(x, GeLU, label = 'GeLU')
plt.legend()
fig.savefig("relu_gelu.pdf")

name='mse'
fig = plt.figure(figsize=(6,6))
initialize_plot()
y = x**2
plt.plot(x, y, label = name)
plt.legend([name])
fig.savefig(name + ".pdf")

name='mae'
fig = plt.figure(figsize=(6,6))
initialize_plot()
y = abs(x)
plt.plot(x, y, label = name)
plt.legend([name])
fig.savefig(name + ".pdf")

def huber_loss(x, d):
    return (abs(x)<=d)*x**2/2 + (abs(x)>d)*d*(abs(x)-d/2)
fig = plt.figure(figsize=(6,6))
initialize_plot()
plt.plot(x, x**2/2, label=r'$x^2/2$')
plt.plot(x, huber_loss(x, 1), label=r'huber: $\delta$=1')
plt.legend()
fig.savefig("huber.pdf")
\end{lstlisting}
\Thanks

时光荏苒，岁月如梭。转眼间，近四年的本科生活就要结束了。这四年是充满了挑战
和挫折的四年，同时也是充满了丰收和果实的四年。值此毕业论文致谢之际，
我首先需要特别感谢的是我的毕业论文指导老师，兰州大学信息科学与工程学院的任超
副教授。任老师治学严谨，对我的论文写作极其认真负责。每当我遇到困难请教任老师
时，任老师总能事无巨细地耐心讲解。同时，任老师极高的专业素养与渊博的学识也十分
令我钦佩！在任老师带领的论文写作过程中，我的科研素养得到了极大地提高，获得了许多
十分宝贵的知识和经验。

其次，我要感谢兰州大学提供的一流教学环境与教育资源，兰州大学信息科学与工程
学院的各位老师的专业教导，以及兰州大学信息科学与工程学院2018级计算机科学与技术
基础理论班的各位同学，以及舍友和其他同学的支持与鼓励。四年的朝夕相处，是他们
让我拓宽了视野，掌握了基本的计算机专业知识和技能，并且让我获得了学习的动力，
为我的继续深造以及未来工作打好了坚实的基础，从而让我能够更好地为社会贡献自己
的力量。在后续的学习工作生活中，我必将以梦为马，不负韶华！

最后，我要感谢大学四年父母对我的默默关爱和支持，让我能够顺利地完成本科学业。
父母对我的无私且伟大的爱，是我在黑暗中的灯塔，给予了我不断前行的动力。

另外，本文使用的数据集下载于“国家青藏高原科学数据中心”(http://data.tpdc.ac.cn)。
在写作时从GitHub中获取并使用了兰州大学2016级物理科学与技术学院本科生余航
制作的“兰州大学本科生2021学士学位毕业论文LaTeX模板”，在此也一并致谢。

\end{document}