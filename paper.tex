% !TEX TS-program = xelatex
% !TEX encoding = UTF-8 Unicode

% \documentclass[AutoFakeBold]{LZUThesis}
\documentclass[AutoFakeBold]{LZUThesis}

\begin{document}
%=====%
%
%封皮页填写内容
%
%=====%

% 标题样式 使用 \title{{}}; 使用时必须保证至少两个外侧括号
%  如： 短标题 \title{{第一行}},  
% 	      长标题 \title{{第一行}{第二行}}
%             超长标题\tiitle{{第一行}{...}{第N行}}

\title{{基于 ICEEMDAN 多特征分解和Prophet-}{GRU-NN组合模型多步预测短期风速}}



% 标题样式 使用 \entitle{{}}; 使用时必须保证至少两个外侧括号
%  如： 短标题 \entitle{{First row}},  
% 	      长标题 \entitle{{First row}{ Second row}}
%             超长标题\entitle{{First row}{...}{ Next N row}}
% 注意：  英文标题多行时 需要在开头加个空格 防止摘要标题处英语单词粘连。
\entitle{{Multistep-Ahead Forecast Short-Term Wind Speed }{through ICEEMDAN Decomposed Multi-features }{and Prophet-GRU-NN Hybrid Model}}

\author{蒋嵩林}
\major{计算机科学与技术（基础理论班）}
\advisor{任超}
\college{信息科学与工程学院}
\grade{2018级}



\maketitle

%==============================%
% ↓ ↓ ↓ 诚信说明页 授权说明书
%==============================%

% 1. 可以调整签字的宽度，现在是40
% 2. 去掉raisebox的相关注释(注意上下大括号对应)，可以改变-5那个数字调整签名和横线的上下位置

% 你的签名，signature.pdf 改为你的签名文件名，
\mysignature{
    % \raisebox{-5pt}{
        \includegraphics[width=60pt]{author_sig.pdf}
    % }
}
% 你手写的日期，signature.pdf 改为你的手写的日期文件名
\mytime{
    % \raisebox{-5pt}{
        \includegraphics[width=90pt]{author_date.pdf}
    % }
}
% % 老师的手写签名，signature.pdf 改为老师的手写签名文件名
% \supervisorsignature{
%     % \raisebox{-5pt}{
%         \includegraphics[width=40pt]{signature.pdf}
%     % }
% }
% % 老师手写的时间，signature.pdf 改为老师的手写的日期文件名
% \teachertime{
%     % \raisebox{-5pSt}{
%         \includegraphics[width=40pt]{signature.pdf}
%     % }
% }
% % 老师手写的成绩
% \recommendedgrade{
%     % \raisebox{-5pt}{
%         \includegraphics[width=40pt]{signature.pdf}
%     % }
% }

\makestatement

%==============================%
% ↑ ↑ ↑ 诚信说明页 授权说明书
%==============================%

\frontmatter



%中文摘要
\ZhAbstract{
风能，作为一种清洁可再生新能源，正在世界范围内飞速发展。
准确预测风速来服务于风力发电，意义重大。

风速预测是一个时间序列回归问题，由于短期风速的波动具有随机性，其影响因素也十分复杂，
呈现出非平稳且非线性的特征，单独预测难度较大。本文基于前人研究成果，从数值预报方
法中获得灵感，结合其他易预测的气象要素特征辅助风速预测。对于每个特征选用最前沿的
ICEEMDAN分解技术，结合Facebook推出的新型Prophet时间序列预测框架分析特征，并根据从
SVR中获得的灵感，使用基于RBF的核主成分分析技术，降低时间序列数据复杂度。此外，借助于
当前最新循环神经网络结构GRU，采用最前端的GELU激活函数、Nadam优化器、Huber损失函数
应用于神经网络，形成ICEEMDAN-Prophet-GRU模型。最后使用神经网络（NN）整合每个特征
的预测结果，校正风速预测值，提高模型的泛化能力。

选用真实发电场所的气象数据验证模型。结果表明，使用本文提出的多特征
ICEEMDAN-Prophet-GRU-NN模型，提前12小时预测短期风速的精度会明显提升，因而具有优越性。
}{短期风速预测；组合模型；神经网络；深度学习；数据科学}


%英文摘要
\EnAbstract{\fontspec{Times New Roman} {
As one of the clean and renewable energy, wind power is growing rapidly worldwide.
It is of great significance to accurately predict wind speed in order to serve
wind power generation.

Wind speed prediction is a time series regression problem. Due to the
randomness of short-term wind speed fluctuations as well as its complex
influencing factors, which show non-stationary and nonlinear characteristics,
it is challenging to get predicted alone. Based on previous research, this
paper draws inspiration from numerical weather forecasting methods that
combine the other easily predictable meteorological elements to assist
wind speed forecasting. For each feature, the most advanced ICEEMDAN
decomposition technology is selected, combined with the new Prophet time
series prediction framework proposed by Facebook to analyze the feature.
Based on the inspiration obtained from SVR, the RBF Kernel Principal Component
Analysis technology is also used to reduce the complexity of time series data.
Moreover, with the help of the current latest recurrent neural network
structure GRU, the most high-end GELU activation function, Nadam optimizer,
and Huber loss function are also applied to the neural network to form the
ICEEMDAN-Prophet-GRU model. Finally, a Neural Network is used to integrate
the prediction results of each feature, correct the predicted value of wind
speed, and improve the generalization ability of the model.
    
We use meteorological data from the actual power station to verify the model.
The results show that by using the multi-feature ICEEMDAN-Prophet-GRU-NN
model proposed in this paper, we can significantly improve the accuracy of
short-term wind speed prediction 12 hours in advance, so it has supremacy.
}}
{short-term wind speed forecast, 
hybrid model, neural network, deep learning, data science.
}

%生成目录
\addtocontents{toc}{\protect\thispagestyle{empty}}
\tableofcontents

%生成图表目录（图表不多的话可以给下部分注释掉）
%
\begingroup
\pagenumbering{gobble}
\renewcommand{\addvspace}[1]{}
\newcommand{\loflabel}{图} 
\renewcommand{\numberline}[1]{\loflabel~#1\hspace*{1em}}
\listoffigures
\thispagestyle{empty}

\newcommand{\lotlabel}{表}
\renewcommand{\numberline}[1]{\lotlabel~#1\hspace*{1em}}
\listoftables
\thispagestyle{empty}
\clearpage
\endgroup
%

%文章主体
\mainmatter

\chapter{绪 \qquad 论}

% ！学校要求的规范，绪论是单独的，不是第一章，但是老师们都是让作为第一章，这里我把它放在了论文里。
% 如果你要让在外面，只需要把上面的 \chapter{绪 \qquad 论} 这一句话删去，下面两行去掉注释就行了。
% \addcontentsline{toc}{chapter}{绪 \qquad 论}
% \chapter*{绪 \qquad 论}

% \Intro{
\section{选题研究背景及意义}
\subsection{风力发电的前景}
随着工业发展的需要，人类社会对能源的依赖度也在逐步上升。第二次能源革命以来，
传统化石燃料的使用导致了一系列的问题。化石燃料在开采过程中产生了
一系列的环境问题。以煤炭为例，在开采时，会破坏地表原本的性状，引发滑坡，塌陷
等一系列问题。开采煤炭所产生的废渣也难以处理，产生的污水会对水土环境造成污染。
同时，燃烧化石燃料所产生的二氧化硫($SO_2$)和氮氧化物会形成酸雨，粉尘使空气能
见度降低，一氧化碳(CO)和芳香烃化合物会污染空气；二氧化碳($CO_2$)在大气层中所
占比例的提高，也导致了温室效应与气候变化，从而使得一些极端天气灾害的发生频率
有了显著的升高。然而目前，在世界能源消费占比中，煤炭和石油的比重仍较多。
我国的能源生产和消费构成中，煤炭在2019年仍在一次能源中占比57.7\%，石油
则占比19.6\%，占据着主要地位。\upcite{能源数据2021王庆一}

当前传统化石燃料，由于其储量的有限性，也正逐步面临枯竭的风险。“绿水青山就
是金山银山”。可再生能源的发展，不仅将会确保绿水青山的存在，而且同时也必然即
将成为金山银山的重要组成部分。过去三十年以来，风能一直保持着最快增长的可再
生能源的记录，是目前全球第二大的可再生能源。风能本质上属于一种气象能源，其
为太阳照射环境下地球表面受热不均，在水平气压梯度力的影响下，由于温差造成大
气对流所产生的一种能量来源。李仲蔚的研究
\upcite{李仲蔚2019风力发电企业价值评估研究}估算结果表明，全球可开发
利用的风能资源达到了二千万兆瓦($2\times10^7MW$)，是目前全球第一大的可再生
能源水能的10倍。风能因其分布广泛，弥补了水能发电需要的苛刻条件以及对生态自
然环境可能造成不良影响的缺陷。如将预估的可利用风能的1\%加以利用，即可以满
足全球能源的发电使用需求，因而发展潜力极其巨大，十分有望在将来替代水能成为
全球第一大可再生能源。

\subsection{短期风速预测的意义}
对于短期近地面风速的预测能够很好的帮助并促进风能的应用。首先，风力发电电网管理人员
可以通过预测结果优化电力分配，提高发电量；其次，风力发电厂还可以准确地在风速
过大之前对风力发电机指示停机，预防风力发电机的过载损毁，避免或者减少相应的损
失；最后，还可以有效安排好风力发电的电网并网问题，减少因为风速的剧烈波动对电
网发电稳定性的影响，降低运营成本，增加风电场的效益。

某地的短期风速主要受气象因素影响，这些气象要素主要包括温度、气压、
湿度等。对于目前的风速预测研究而言，相关问题主流使用的模型包括传统时间序列模型以及
深度学习模型。它们各自都存在许多优点和一定的缺陷，并且单一模型并不能很好地进行预测。
\upcite{陆冰鉴2020基于}
通过组合模型，结合各模型的优势，对其进行精确地预测，取长补短，将会对风力发电的应
用起到巨大的促进作用。同时，由于风速数据中往往包含着较大的噪声问题，如何
有效地对其数据集进行降噪处理也是目前研究的方向之一。

\section{选题已有研究成果综述}
\subsection{数值预报方法}
数值预报方法以流体力学方程和热力学方程等基本方程为依据来实现整个大气状态模型
（数值预报模式）的构建，随后使用大气压、气温、相对湿度、风速等数值型数据来作为初
始状态，通过超级计算机进行数值计算求解，得到未来天气的预报结果。
\upcite{姜兆宇2019多时空尺度的风力发电预测方法综述}

目前数值预报方法已经很成熟，准确性良好，已经广泛地应用到了天气预报中。
但是，由于数值方法需要占用大量的计算资源，难以将时间和空间分辨率
做得很高，且短期风速中蕴含的噪声较大，因而单纯的数值预报一般不适用于短期风速预报。
朱智慧等人\upcite{朱智慧2010T639}将基于T639全球中期数值预报产品得到的上海
南汇站24小时风速预报结果利用逐步回归分析结合Kalman滤波得出的MOS方程
进行订正，结果表明其订正后的精度可以考虑投入实际使用。夏晓玲等人
\upcite{夏晓玲2019贵州省数值预报风速产品检验及订正}利用数值预报的
ECWMF，GRAPES和JAPAN模式对于贵州省范围内84个站点的风速预报进行了分析，最终
运用神经网络对3种模式风速预报进行订正，结果表明其误差，正确率订正改善效果
明显，但是相关系数的提高较小。

\subsection{统计与传统机器学习方法}
不同于数值预报方法，统计与传统机器学习方法基于风速历史数据的时间序列，
通过训练机器学习模型来进行预测，并且可以对数据进行预处理，从而可以
从历史数据中挖掘出风速数据的潜在规律，因而相对于数值预报方法，模型的训练
和预测更加简单，无需使用超级计算机进行大量的计算。

\begin{itemize}
\item[a. ] 统计方法：
\end{itemize}

经典的统计方法中对于时间序列数据的处理一般采用自回归综合移动平均模型
（ARIMA, AutoRegressive Integrated Moving Average）。其采用过去观
测值的线性函数关系预测未来值。但是由于风速的时间序列数据普遍是非平稳的，
包含了很强的季节性，因此相关研究普遍采用季节性自回归综合移动平均模
型（SARIMA, Seasonal AutoRegressive Integrated 
Moving Average）。SARIMA是Box和Jenkins提出的ARIMA模型的一个扩展，
用于处理具有季节特征的时间序列数据。Sun, R. N.等人\upcite{2017Forecast}
同时基于ARIMA和SARIMA模型提前24小时预测小时平均风速和风力发电量。并进行了
平均相对误差的比较分析。结果表明，SARIMA模型的预测效果明显优于ARIMA模型。

SARIMA本身机理决定了SARIMA无法处理非线性
时间序列特征，因而在呈现出非平稳且非线性特征的风速时间序列预测中表现
并不是很好。Haddad等人\upcite{haddad2019wind}基于SARIMA方法构建了一个
太阳能和风能预测模型，对于风能预测而言最终效果不是很突出。
Xl, A等人\upcite{2021Short}使用SARIMA模型来预测苏格兰沿海地区
的每小时实测风速。结果表明尽管SARIMA在风速预测的性能与准确度在相互权衡之后
相对于循环神经网络方法具有优越性，但是其预测的风速准确度并不是很理想。

\begin{itemize}
\item[b. ] 机器学习方法：
\end{itemize}
 
传统机器学习方法，在风速中应用最广泛的为支持向量回归机（SVR，
Support Vector Regression）。支持向量回归机是支持向量机
（SVM，Support Vector Machine）的一个非常重要的变体，其将SVM
的应用领域从分类变成了回归。SVR的目标是对时间序列输入数据的每个点
通过非线性变换寻找一个最优超平面。不同于SVM的最优超平面需要使得两类
或多类样本点与超平面之间的总偏差最大，SVR的样本点最终只有一类，
并且其最优超平面需要所有的样本点与超平面之间的总偏差最小。

传统的SVR能够对非线性特性的数据有较好的预测能力，然而由于风速呈现
出非平稳的特征，其非线性关系复杂，且其中所含噪声较多，直接对风速进行预测无法达到很好的
效果。朱霄旬等人\upcite{朱霄旬2017遗传算法对}使用一种基于遗传算法
(GA，Genetic Algorithm)的多参数同步优化算法，改进了传统通过相空
间重构法求出SVR预测模型的最优参数的方法，并大大提高了预测精度。
Pan, C.等人\upcite{2018Hybrid}首先根据回归率和确定性相结合的联合指数，
对风速序列的可预测性进行了定量分析，然后利用联合指数优化的参数重建风速
序列，通过嵌入维数和延迟时间得到预测模型的最佳输入集。最终利用布谷鸟优化
算法（COA，Cuckoo Optimization Algorithm）优化的SVR模型对风速进行预
测，取得了不错的效果。

\subsection{深度学习方法}

近年来，随着深度学习的发展，深度学习方法在风速预测中的应用越来越广泛。
深度学习由数据驱动，具有十分强大的泛化能力，十分适合处理具有非平稳且
非线性特征的风速时间序列预测。神经网络模型虽然预测效果好，但是对数据集要求高，
存在训练难度大，容易产生过拟合、梯度爆炸、梯度消失等一系列问题。

Shivani等人\upcite{Shivani2019A}对传统时间序列统计模型ARIMA和
一个深度学习模型预测风速进行了比较研究。该深度学习模型由长短期记忆网络
（LSTM，Long Short-Term Memory）和循环神经网络
（RNN，Recurrent Neural Network）组合而成，结果凸显了深度学习预测风速
在精度上的优越性。Alencar, D. B.等人\upcite{alencar2018hybrid}提出了一种基于
SARIMA和反向传播（BP，Back Propagation）神经网络的组合模型方法，
用于多步超前风速预测。并进行了仿真分析。其结果表明，对于不同的预测时段，
该组合模型预测方法的预测精度优于大部分传统算法。朱丽娜的研究
\upcite{朱丽娜2021风电}得出结论：LSTM适用于预测非平稳序列风速，Elman神经
网络，一种动态递归神经网络，次之。

由于风速数据的非平稳性，其时间序列数据中往往掺杂着较大的噪声。这些噪声
如果不分离出来，将会一定程度上影响到深度学习模型对风速时间序列的预测精度
和泛化能力，加大对其非线性关系的学习难度。许多常见的信号分解技术包括傅里叶
变换以及小波变换，将时间序列信号从时域变换到频域，从而将高频噪声分离。
常见的降噪方法包括小波分解（WD，Wavelet Decomposition）、
变分模式分解（Variational Mode Decomposition）、Hilbert-Huang变换
（HHT，Hilbert-Huang Transform）以及经验模式分解
（EMD，Empirical Mode Decomposition）以及基于上述四类方法演化出的
一系列分支。

谢义超\upcite{谢义超2021基于}提出了一种基于CEEMDAN分解和改进的LSTM模型。
该模型基于粒子群优化算法（PSO，Particle Swarm Optimization）与样本熵
选择CEEMDAN以及LSTM的超参数，从而让参数达到最优值。最终得出的结果表明，
CEEMDAN分解技术可以极大地提高基于循环神经网络模型的泛化能力，降低模型
的训练难度。王秀的研究\upcite{王秀2021基于}基于小波变换，通过SARIMA和
LSTM模型的组合，提升了对短期风速的预测精度。

\section{论文研究内容与组织结构}

随着数据科学的发展，使用开箱即用（Out of the box）的数据分析框架
已经成为数据科学研究的一种新潮流。在这之中包括了流行的机器学习框架
scikit-learn，以及时间序列数据处理预测框架Prophet。

由于注意到直接使用Prophet框架来进行非平稳非线性的风速预测效果并不佳，因而
本文基于上述前人研究成果，决定选取数值天气预报中常见的五种气象要素历史数据，
其包括地面向下长波辐射、近地面气压、近地面空气相对湿度、地面向下短波辐射、近地面气温，结合近地面全
风速的历史数据构建短期风速的预测模型。首先，采用当前科研最前沿的改进自适应噪声完备
集合经验模态分解（ICEEMDAN）算法，对上述六种特征历史数据进行分解，将高频噪声和
低频信号进行分离，降低时间序列数据分析的复杂度，从而提高准确性。然后，将分解结
果序列按照八个时刻预测未来一个时刻的滑动窗口方法形成样本，输入由 Facebook 推出的主
流时间序列预测框架 Prophet 进行统计分析，得到Prophet拟合的结果以及统计分析
得出的趋势分量、累加式季节性分量以及上述分量所对应的最大边界和最小边界。这些处理
后的数据进一步降低了六种特征对应时间序列的复杂度，便于神经网络的训练。最终，将所有由
Prophet分析的时段对应的结果和原始数据一起进行基于高斯径向基函数（RBF）的核
主成分分析（KPCA），将数据升维，分解非线性相关，更进一步降低了数据复杂度。然后输入
进一个由两层门控循环单元（GRU）构成的深度学习模型，采用最新科研成果 Nadam 优化器
以及 Huber损失函数训练模型，并部分应用GELU激活函数，输出每个时段预测的六种气象要素
值，最终使用基于RBF的核主成分分析（KPCA）将预测结果再次升维，输入进一个由三个全连接
层、一个随机丢弃层构成的神经网络（NN）进行修正，最终得到预测的近地面全风速值。

为了验证模型的实际效果，本文选取了甘肃中电酒泉第四风力发电有限公司附近（北纬
40.65 度，东经 96.95 度）的2017年1月1日0时整至2018年12月30日21时整
\footnote{此处所述时间均为协调世界时(UTC, Universal Time Coordinated)。}间
隔三小时的历史数据，通过四步预测未来12小时的风速值，并使用多项指标以及对模型的预
测结果进行可视化分析，对比模型各要素的优劣，从而对模型全方面综合评估，最终验证模型的优越性。

论文的结构如下：

第一章：绪论。主要讲述选题缘由，风速问题研究背景以及意义，以及对现有研究
方法的综述。

第二章：数据来源及特征提取。主要讲述特征的选取原因以及数据集的制作过程。
对选取数据集的性状进行了分析，通过统计学方法验证特征选取的正确性。

第三章：使用技术的介绍和比较。主要讲述现有主流技术，并进行技术分析对比，讲述
最终选择ICEEMDAN分解技术、Prophet、基于RBF的KPCA、GRU网络、Nadam 优化器、
Huber损失函数以及GELU激活函数的原因。

第四章：模型的建立和评估。主要讲述模型的评估指标介绍、细节、训练以及调参过程，
并与只使用单个或多个本文提出的组合模型中的成分进行组合的其它简单模型进行对比。

第五章：总结与展望。对全文进行总结，指出创新点与有待进一步研究的方向。

% }


% % =======正文从第一章开始
% \setcounter{chapter}{0}

\chapter{数据来源及特征选取}
\section{数据来源}
本文数据来源于中国区域地面气象要素驱动数据集（1979-2018）
\upcite{8028b944-daaa-4511-8769-965612652c49}，该数据集常用于数值天气
预报，包括地面向下长波辐射、地面降水率、近地面气压、近地面空气比
湿、地面向下短波辐射、近地面气温、近地面全风速共7个气象要素。数据时间
分辨率为3小时，水平空间分辨率为0.1°，为netCDF格式。
\upcite{37cab0ac-d066-4fb9-aa9c-1cf50d601096}

该数据集基于世界上现有的GLDAS数据、普林斯顿再分析数据、GEWEX-SRB辐射
数据和TRMM降水数据，并整合了中国气象局的常规气象观测数据，去除了非物理范围值，
对于缺失数据采用ANUSPLIN统计插值。该数据集的精度介于气象局的观测数据
和卫星遥感数据之间，优于世界上现有的再分析数据。\upcite{6bab74c1-f2dd-4e24-a833-81f33bedf9b1}

\section{特征选取与数据集的制作}
本文数据集基于上述中国区域地面气象要素驱动数据
集（1979-2018）构建而成，通过Python语言netCDF4库
\footnote{提取所用代码请见附录部分A.1}
选取了数据集中的全部气象要素，并选择了甘肃中电酒泉第四风力发电有限公司附近
（北纬40.65 度，东经 96.95 度，见图\ref{fig_google_maps}，坐标局部范围
可见清晰的风力发电机组）的2017年1月1日0时整至2018年12月30日21时整
\footnote{此处所述时间均为协调世界时(UTC, Universal Time Coordinated)。}
共5832条数据。

\begin{figure}[H]
    \centering
	\subfloat[甘肃省范围内]{
        \includegraphics[width=0.88\textwidth]{figures/google_maps.pdf}
    } \\
	\subfloat[局部范围内]{
        \includegraphics[width=0.88\textwidth]{figures/google_maps_details.pdf}
    }
    \caption{选址地坐标使用谷歌地图绘制出的卫星地图}
    \label{fig_google_maps}
\end{figure}

生成数据格式为CSV（逗号分隔值，Comma-Separated Values）文件，包
含数据内容如表\ref{features}所示：

\begin{table}[H]
    \centering
    \caption{数据集中所包括特征值的单位以及含义说明}
    \begin{tabular}{cccc}
    \toprule
    特征 & 名称 & 单位 & 含义 \\
    \midrule
    ds & 日期 & UTC & 数据格式为：YYYY-mm-dd HH:MM:SS \\
    lrad & 地面向下长波辐射 & $W/m^2$ & 从当前时间1.5小时前开始的3小时平均值 \\
    prec & 地面降水率 & $mm/h$ & 从当前时间3小时前开始的3小时平均值 \\
    pres & 近地面气压 & $Pa$ & 近地面(距地面2米处)瞬时值 \\
    shum & 近地面空气相对湿度 & 比值，无单位 & 近地面(距地面2米处)瞬时值 \\
    srad & 地面向下短波辐射 & $W/m^2$ & 从当前时间1.5小时前开始的3小时平均值 \\
    temp & 近地面气温 & $K$ & 近地面(距地面2米处)瞬时值 \\
    wind & 近地面全风速 & $m/s$ & 近地面(距地面2米处)瞬时值 \\
    \bottomrule
    \end{tabular}
    \label{features}
\end{table}

\section{特征数据分析}
\subsection{描述性统计分析}

\begin{table}[H]
    \centering
    \caption{七种气象要素的描述性统计分析}
    \begin{tabular}{cccccccc}
    \toprule
    指标 & lrad & prec & pres & shum & srad & temp & wind \\
    \midrule
    算术均值 & 269.5 & 0.009 & 85519.502743 & 0.002993 & 192.962834 & 281.441822 & 4.040625 \\
    标准差 & 64.77 & 0.085995 & 610.557534 & 0.002663 & 267.761536 & 13.806527 & 2.357598 \\
    最小值 & 132.3 & 0 & 83722 & 0.000015 & 0 & 245.629990 & 0.051998 \\
    25\%值 & 216.3 & 0 & 85049.5 & 0.001129 & 0 & 270.36 & 2.285995 \\
    50\%值 & 265.5 & 0 & 85518 & 0.001971 & 3 & 282.754990 & 3.529999 \\
    75\%值 & 321.1 & 0 & 85972 & 0.004012 & 352.5625 & 292.5825 & 5.258496 \\
    最大值 & 449.5 & 2.692501 & 86820 & 0.015863 & 989.5 & 311.25 & 16.23 \\
    极差 & 317.3 & 2.692501 & 3098 & 0.015848 & 989.5 & 65.620010 & 16.178002 \\
    四分位差 & 104.8 & 0 & 922.5 & 0.002883 & 352.5625 & 22.2225 & 2.972501 \\
    离散系数 & 0.24 & 9.609496 & 0.007139 & 0.889654 & 1.387633 & 0.049056 & 0.583474 \\
    平均离差 & 54.69 & 0.016437 & 508.073047 & 0.002045 & 223.512922 & 11.758743 & 1.844962 \\
    偏态 & 0.181 & 19.269338 & 0.002976 & 1.563321 & 1.211468 & -0.237797 & 1.115041 \\
    峰度 & -0.87 & 443.377569 & -0.722968 & 2.034095 & 0.202964 & -0.892140 & 1.404610 \\
    \bottomrule \\
    \end{tabular} \\
    \raggedright
    \footnotesize{该表格数据生成代码见附录部分A.2}
    \label{analysis}
\end{table}

使用python的pandas库自带的统计功能计算得到表\ref{analysis}中统计数据。
由表\ref{analysis}统计数据可见，选址地2017-2018年两年全年最低气温-27.5$^{\circ}$C，
最高38.1$^{\circ}$C，昼夜温差较大，冷热对流明显。同时该地区降水非常稀少，空气干燥，太阳
辐射强，易产生空气的稳定辐射型对流。该地区出现过的最大风力为7级（16.23 m/s），
风力平均为3级（4.04 m/s），因而风速较大，且风速的方差较小，风力资源丰富且相对稳定，
的确是风力发电的一个很好的选址。

\subsection{相关性分析和显著性检验}
因为传统的皮尔逊（Pearson）相关系数衡量的只是线性相关关系，并且皮尔逊相关系数
对数据的要求较高，不适用于非平稳且非线性的风速数据。因而这里采用可以度量单调关
系的斯皮尔曼（Spearman）相关系数。使用python的scipy库相关方法计算得到
表\ref{relativity-analysis}中统计数据。

\begin{table}[H]
    \centering
    \caption{风速与其他六种气象要素的斯皮尔曼相关性分析}
    \begin{tabular}{lll}
    \toprule
    wind & 相关系数 & 显著水平 \\
    \midrule
    lrad & $0.032350777005598^{**}$ & 0.013486168347444174 \\
    prec & $0.007876001330736$ & 0.5476061053614518 \\
    pres & $0.074690860912321^{**}$ & $1.1250462841430117\times10^{-8}$ \\
    shum & $-0.08556207603753^{**}$ & $5.958774799092212\times10^{-11}$ \\
    srad & $0.246264995629444^{**}$ & $2.650405346230128\times10^{-81}$ \\
    temp & $0.056715012962243^{**}$ & $1.4659365394277926\times10^{-5}$ \\
    \bottomrule \\
    \end{tabular} \\
    \raggedright
    \footnotesize{该表格数据生成代码见附录部分A.3} \\
    \footnotesize{$^{**}$ 表示在0.01级别（双尾），相关性显著}
    \label{relativity-analysis}
\end{table}

由表\ref{relativity-analysis}所示，排除由于选址地区降水数据过于稀少，导致地面
降水率与其相关性不大的因素，
风速与其他剩余五种气象要素的相关系数都较大，有较强的相关性，并且相关性都在99\%
的置信水平下通过检验，相关性极其显著。其中与风速相关性最强的是地面向下短波辐射。

最终根据上述过程中的数据分析，去除掉地面降水率这一特征，保留剩余的地面向下长波辐射、
近地面气压、近地面空气相对湿度、地面向下短波辐射、近地面气温共计五种特征。


\chapter{使用技术的介绍和比较}
\section{基于EMD的信号分解技术}
\subsection{EMD}
经验模态分解（EMD，Empirical Mode Decomposition）是一种适用于处理非平稳
非线性时间序列的自适应时空分析方法，由Huang, Norden E等人于1998年
提出\upcite{huang1998empirical}。EMD在不离开时域的情况下将序列划分为
有限个本征模函数（IMF，Intrinsic Mode Function）和残差。分解出的IMF
可以提供一个时间序列中包含的各种信号的特征。与傅里叶变换和小波分解等类似，
EMD分解不是基于物理性质。但是，EMD可以依据信号自身的时间尺度特征对信号没有任何
先验主观标准选择地自动分解，因而无需像傅里叶变换与小波分解一样设定谐波
基函数或小波基函数。

在时域范围内具有以下条件特征的时间序列，可以使用EMD分解：
\begin{itemize}
\item 局部的时域特性仅由极值点间的时间尺度唯一确定。
\item 至少存在一个极大值点和一个极小值点。
\item 若存在拐点但无极值点，可通过多次微分求得极值，然后积分计算分解结果。
\end{itemize}

分解出的本征模函数在时域范围内满足如下两个性质：
\begin{itemize}
\item 极值点和过零点的数目相等或相差一个。
\item 上包络线（极大值点的包络线）和下包络线（极小值点的包络线）均值为0。
\end{itemize}

EMD分解步骤如下：
\begin{itemize}
\item[1. ] 找出待分解时间序列$X(t)$的所有极大值点，并将所有极大值点用三次样条插值
函数拟合形成原数据的上包络线。
\item[2. ] 同理，找出待分解时间序列$X(t)$的所有极小值点，并将所有极小值点用三次样
条插值函数拟合形成数据的下包络线。
\item[3. ] 设上包络线和下包络线的均值函数为$M(t)$，设$H(t)=X(t)-M(t)$，得到新的
时间序列$H(t)$。如果$H(t)$不满足本征模函数的两个性质，则对$H(t)$重复步骤
1-3，否则得到一个IMF分量$H(t)=IMF_i(t)$。
\item[4. ] 对$M(t)$重复步骤1-3，直到$M(t)$不满足使用EMD分解
的条件，则$R(t)=M(t)$，R(t)为残差。
\end{itemize}

由上述推导过程可得：
$$
X(t)=\displaystyle\sum_{i=1} ^n IMF_i(t) +R(t)
$$

\subsection{EEMD}

集成经验模态分解（EEMD，Ensemble Empirical Mode Decomposition）是一种
噪声辅助数据分析方法，其将用于筛选的白噪声附加在原始时间序列上。
EEMD由Wu, Zhaohua等人提出\upcite{wu2009ensemble}。他们的
研究发现，在EMD分解的IMF分量筛选过程中，添加一定的白噪声可以平滑极值点的分布，
从而能够让分解过程考量到尽多可能的解并进行筛选，使得分解的结果更加健壮。由于
白噪声可以通过足够多的平均迭代抵消，从而在此平均化过程中唯一留存下来的
部分就是更真实且更具物理意义的时间序列。

EEMD分解步骤如下：
\begin{itemize}
\item[1. ] 对待分解时间序列$X(t)$添加一个随机白噪声序列$N(t)$，得到新序列$K(t)$。
\item[2. ] 对$K(t)$进行EMD分解。
\item[3. ] 对步骤1-2重复n次，将得到的共计n组的每个IMF分量和残差按组进行系综平均（Ensemble Average）。
\item[4. ] 得到系综平均后的IMF分量和残差。
\end{itemize}

\subsection{CEEMDAN}
自适应噪声完备集合经验模态分解（CEEMDAN，Improved Complete Ensemble
Empirical Mode Decomposition with Adaptive Noise) 由Torres
等人提出\upcite{torres2011complete}。它是EMD的改进版本，
同时又借鉴了EEMD的思想，提供了对原始信号的精确重建和对本征模函数（IMF）的
更好的频谱分离。

CEEMDAN分解步骤如下：
\begin{itemize}
\item[1. ] 对待分解的时间序列$X(t)$添加一个幅值为r的白噪声序列$N(t)$，得到新序列$K(t)$。
\item[2. ] 对$K(t)$进行一次EMD分解迭代，得到一个IMF分量。
\item[3. ] 对步骤1-2重复n次，将得到的共计n组的IMF进行系综平均（Ensemble Average），得到$IMF_i(t)$
用$X(t)-IMF_i(t)$作为新序列，返回步骤1迭代j次。
\item[4. ] 最终不能进行EMD分解时$X(t)-IMF_i(t)$得到残差R。
\end{itemize}

CEEMDAN相较于EEMD方法有如下优点：

\begin{itemize}
\item EEMD方法需要通过足够多的平均迭代抵消白噪声，因而往往所有IMF分量和
残差R直接相加复原出的原信号并不准确。而CEEMDAN在较小的平均次数下就可以有很好
的可复原性。
\item 相较于EEMD，CEEMDAN无需计算过多的平均值，因而分解的性能要更高。
\item EEMD分解一般会出现多个无意义的低幅值低频伪IMF分量，CEEMDAN可以减少该种情况
出现的频率。
\end{itemize}

\subsection{ICEEMDAN}

ICEEMDAN由Colominas等人提出\upcite{colominas2014improved}，其为CEEMDAN的改进版本。
ICEEMDAN将上述CEEMDAN方法步骤1的重复迭代过程中的第x次迭代时使用的噪声更改为使用原第一次添加噪声
的对噪声进行EMD分解的第x个IMF分量，并使用该噪声的第x个IMF分量和添加的噪声相对于待分解
时间序列的信噪比相乘，再除以白噪声的标准差。

ICEEMDAN分解相对于CEEMDAN进一步降低了出现多个无意义的低幅值低频伪IMF分量的频率。

由于ICEEMDAN是基于EMD的信号分解技术的集大成者，因而本文最终决定选用ICEEMDAN。

\section{基于Prophet框架的时间序列预测方法}
Prophet\upcite{taylor2018forecasting}是由Facebook于2018年提出的一种时间序
列预测算法框架。其核心部分使用类似于SARIMA的方法进行时间序列预测，可以
学习年、周、月和日的季节性以及假日效应等非平稳周期性趋势，最适用于具有强烈季节性影响的时
间序列，并且可以通过R和Python实现调用。Prophet的预测速度快，不同于SARIMA需要手动
对时间序列进行处理判断以及定阶，Prophet提供了完全自动化的时间序列预测功能，因而
无需手动操作即可对杂乱的数据进行合理预测。其对异常值、缺失数据和时间序列中的剧烈
变化也都具有十分强大的健壮性，并且为用户提供了许多超参数，支持通过交叉验证进行超参数调优。

Prophet的算法模型为：
$$y(t)=g(t)+s(t)+h(t)+\epsilon_t$$

该公式中g(t) 表示的是趋势分量，代表时间序列数据在非周期性规律中的变化趋势；
s(t) 表示周和日、年的季节性分量；h(t) 表示节假日项，此处和风速预测无关；
$\epsilon_{t}$为残差，表示噪声分量，其服从高斯白噪声分布。

\section{基于PCA的降维方法}
\subsection{主成分分析}
主成分分析（PCA，Principal Component Analysis）是一种基于线性变换降低数据集的维度
，从而达到简化数据集目的的方法。其利用正交变换，对一系列可能的相关变量的观测值进行线性
变换，从而将其投影为一系列线性不相关的变量特征，并同时保留对彼此差异贡献最大的特征。
这种变换这是通过忽略高阶成分并保留低阶成分并来实现的。

假设待降为的原始数据有m条，每条数据为n维，组成了n行m列的矩阵X，则PCA的算法步骤如下：

\begin{itemize}
    \item 首先将X的每一行进行零均值化（减去这一行的均值）。
    \item 求解协方差矩阵$C=\frac{1}{m}XX^\mathsf{T}$，以及其特征值及对应的特征向量。
    \item 将协方差矩阵C的特征向量按对应特征值大小从前到后按行排列成矩阵，取前k行组成新矩阵P。
    \item $Y=PX$即为降维到k维后的数据。
\end{itemize}
PCA可以很好的解除线性相关，但是对于非线性的高阶相关性，PCA无法处理
\upcite{jolliffe2016principal}。

\subsection{核主成分分析}
核主成分分析（KPCA）是一种基于核函数的主成分
分析方法，其源于SVR（支持向量回归）思想，通过核函数将非线性相关变换到更高维度，
使其转换为线性相关后再进行主成分分析。因而，KPCA方法可以用于解决非线性的高阶相关性问题，适用于
非平稳非线性关系较强的天气要素数据。

本文核函数使用高斯径向基函数（高斯核函数，RBF核，Radial Basis Function Kernel），
其表达式为：
$$K(\mathbf x_i,\mathbf x_j)=e^{-\gamma\|\mathbf x_i-\mathbf x_j\|^2}$$

图\ref{fig_kpca}展示了KPCA的工作流程：
\begin{figure}[H]
    \centering
    \includegraphics[width=0.4\textwidth]{KPCA.pdf}
    \caption{基于RBF的核主成分分析算法工作流程示意图}
    \label{fig_kpca}
  \end{figure}

与其他核函数相比，选择RBF核函数的原因是：

\begin{itemize}
\item[1. ] RBF为非线性映射核函数，和风速数据中较多的非线性特征契合，并且线性核
函数也只是RBF的一个特例，因而不使用线性核函数。
\item[2. ] 多项式核函数需要计算内积，容易发生数值溢出的问题。
\item[3. ] sigmoid 核函数$K(\mathbf x_i,\mathbf x_j)=\tanh(b\:\mathbf x_i^T\mathbf x_j-c)$
需要同时确定超参数$b$和$c$，确定过程复杂，不易于产生很好的效果。
\end{itemize}

\section{基于RNN的深度学习神经网络模型}
\subsection{经典循环神经网络}
循环神经网络（RNN，Recurrent Neural Network）是一种深度学习模型。经典的神经网络
\upcite{rumelhart1986learning}，由于其时序无关，采用了层状传递结构，
模型的内部前一层神经元数据直接传递给后一层神经元。这样做模型由于无记忆功能，
无法学习时序数据中的历史相关性，因而需要循环层，通过内部传递时序数据来学习。
图\ref{fig_nn}展示了两种神经网络的结构区别。

\begin{figure}[H]
	\centering
	\subfloat[经典BP神经网络]{
        \includegraphics[width=0.5\textwidth]{figures/ANN.pdf}
    }
	\subfloat[经典循环神经网络]{
        \includegraphics[width=0.5\textwidth]{figures/RNN.pdf}
    }
    \caption{两种经典神经网络结构示意图}
    \label{fig_nn}
\end{figure}

神经网络激活函数将神经网络模型中神经单元的输出映射到一个范围，从而起到控制输出数据值域的作用。
常见的神经网络激活函数有如下4种：
\begin{itemize}
\item[a. ] sigmoid
\end{itemize}

$$sigmoid(x)=\frac{1}{1+e^{-x}}$$
\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/sigmoid.pdf}
    \caption{sigmoid函数图像}
    \label{fig_sigmoid}
\end{figure}
如图\ref{fig_sigmoid}所示，sigmoid函数为单调递增函数，在$-\infty$上趋近于0，
在$+\infty$上趋近于1。

\begin{itemize}
    \item[b. ] tanh
\end{itemize}

$$tanh(x) = \frac{e^x-e^{-x}}{e^x+e^{-x}}$$
\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/tanh.pdf}
    \caption{tanh函数图像}
    \label{fig_tanh}
\end{figure}
如图\ref{fig_tanh}所示，tanh函数为单调递增函数，在$-\infty$上趋近于-1，
在$+\infty$上趋近于1，且过原点。其实质上是
sigmoid函数的缩放移动版本。

\begin{itemize}
\item[c. ] ReLU和GELU
\end{itemize}

$$
ReLU=
\left\{\begin{matrix}
    0, & x \leq 0 \\
    x, & x > 0
\end{matrix}\right.
$$

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/relu_gelu.pdf}
    \caption{ReLU和GELU函数图像}
    \label{fig_relu_gelu}
\end{figure}

如图\ref{fig_relu_gelu}所示，尽管整流线性单元（ReLU，Rectified Linear Unit）
计算简单，性能好，但是由于ReLU是线性激活函数，在为正值时梯度始终为1。
而风速数据具有较强的非线性特征，因而用于风速数据效果不是很理想。

高斯误差线性单元（GELU，Gaussian Error Linear Unit）是Hendrycks, Dan等人于2016提出的
\upcite{hendrycks2016gaussian}一种高性能的神经网络激活函数。GELU 激活函数表达式是
$x\Phi(x)$，其中$\Phi(x)$是标准高斯累积分布函数。GELU 是非线性激活函数，其对输入值进行
高斯加权处理，相较于sigmoid和tanh而言能一定程度上避免x值变大时梯度消失的问题
，从而带给循环神经网络训练任务更好的收敛性和拟合效果。

神经网络模型优化器直接参与神经网络的训练，通过对应算法搜索神经网络的最优权重参数。
\footnote{本部分内容参考了Ruder, Sebastian的梯度下降优化算法综述\upcite{ruder2016overview}}
\begin{itemize}
    \item[a. ] SGD
\end{itemize}

随机梯度下降（SGD，Stochastic Gradient Descent）是深度学习神经网络的训练基础算法，
它是一种比较简单的梯度下降算法。假设目标神经网络函数为$J(\theta)$，神经网络的参数值
为$\theta$。则SGD根据固定的学习率η，通过在目标函数梯度的相反方向上$\nabla_\theta J( \theta)$
更新参数$\theta$来搜寻神经网络的参数，使得目标神经网络达到局部最优点。

SGD的更新公式为：
$$\theta = \theta - \eta\nabla_\theta J( \theta)$$

\begin{itemize}
    \item[b. ] Momentum
\end{itemize}

Momentum是Qian, Ning研究出的\upcite{qian1999momentum}一种有助于在梯度下降的
方向加速 SGD 并抑制SGD振荡的方法。它通过添加动量项比值γ，将过去时间步的更新向
量到添加到当前的更新向量，来实现这一目的。

Momentum的更新公式为：
$$
\begin{matrix}
v_t = \gamma v_{t-1} + \eta \nabla_\theta J( \theta)\\
\theta = \theta - v_t
\end{matrix}
$$

\begin{itemize}
    \item[c. ] NAG
\end{itemize}

涅斯捷罗夫加速梯度下降（NAG，Nesterov Accelerated Gradient）\upcite{nesterov1983method}
基于Momentum，通过$\theta - \gamma v_{t-1}$项使其能够预知未来的更新方向，
从而使得更新更加稳定而不至于一直遵循梯度更新的惯性。这种预期性的更新可以防止
梯度更新得太快，从而提高响应能力。NAG显著提高了 RNN 在许多训练任务中的性能
\upcite{bengio2013advances}。

NAG的更新公式为：
$$
\begin{matrix}
v_t = \gamma v_{t-1} + \eta \nabla_\theta J( \theta - \gamma v_{t-1} )\\ 
\theta = \theta - v_t 
\end{matrix}
$$

\begin{itemize}
    \item[d. ] Adam
\end{itemize}

Adam\upcite{kingma2014adam}是一种基于 RMSProp 的优化器，是目前应用最为广
泛的通用型优化器。它能够自动化调整学习率，
对与频繁出现的特征相关的参数执行较小的更新（低学习率），对与不常见特征相关的参数
执行较大的更新（高学习率），同时还能适应稀疏数据，克服学习率急剧下降的问题。
其本质上为带Momentum动量项的RMSProp。

\begin{itemize}
    \item[e. ] Nadam
\end{itemize}

Nadam\upcite{dozat2016incorporating}向Adam优化器中融合了 NAG 的思想，添加
了Nesterov 动量，从而使其获得了NAG的能够预知未来的更新方向的优点，提高其在 RNN 训练
任务中的性能，最终使用Nadam能够取得比Adam更好的效果。

神经网络模型损失函数度量当前权重参数下输出值和真实值之间的误差大小，
常见神经网络模型损失函数有如下3种：
\begin{itemize}
    \item[a. ] 均方损失函数（MSE）
\end{itemize}

$$MSE=\sum_{t=1}^{N}\left(\hat{y}\left(t\right)-y\left(t\right)\right)^2$$

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/mse.pdf}
    \caption{mse函数图像}
    \label{fig_mse}
\end{figure}

MSE 是平方损失函数，如图\ref{fig_mse}所示，其光滑连续且可导，并且随着误差的减小，
梯度也在减小，从而利于函数的收敛。因而MSE适合于对其使用梯度下降算法。但是，由于MSE
的梯度会随着误差的增大而增大，如果样本中存在较多的异常点，MSE 会给这些异常点平方倍
的权重，从而牺牲正常点的回归预测效果。

\begin{itemize}
    \item[b. ] 平均绝对损失函数（MAE）
\end{itemize}

$$MAE=\sum_{t=1}^{N}\left|\hat{y}\left(t\right)-y\left(t\right)\right|$$

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/mae.pdf}
    \caption{mae函数图像}
    \label{fig_mae}
\end{figure}

如图\ref{fig_mae}所示，MAE 是连续且在非零点处可导的，但是由于其是线性损失函数，
梯度始终保持不变。因而在优化器学习率保持不变的情况下，MAE不利于函数的收敛。但是，
由于MAE将异常点和正常点同等看待，因而克服了MSE的缺点。

\begin{itemize}
    \item[c. ] Huber损失函数
\end{itemize}

$$
Huber=
\left\{\begin{matrix}
    \frac{1}{2}(y\left(t\right) - \hat{y}\left(t\right))^{2}, & \left | (y - \hat{y})  \right | < \delta\\
    ((y\left(t\right) - \hat{y}\left(t\right)) - \frac1 2 \delta)\delta, & \left | (y - \hat{y})  \right | \geq \delta
\end{matrix}\right.
$$

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/huber.pdf}
    \caption{huber函数图像}
    \label{fig_huber}
\end{figure}

Huber 损失函数\upcite{huber1992robust}包含了一个超参数 δ。当预测偏差小于 δ 时，
它采用MSE变换形式的平方损失函数；当预测偏差大于等于 δ 时，采用MAE变换形式的线性损失函数，
如图\ref{fig_huber}所示。

Huber 光滑连续且可导，当误差达到临界点δ时随着误差的减小，梯度也在减小，对于异常点
的误差超出临界点δ时，不会给这些异常点很大的权重，从而同时达到一个很好的收敛和预测
效果。因而，Huber同时综合了MSE和MAE的优点并同时克服了他们的缺点。

由上述神经网络的基本原理可知，假设激活函数为sigmoid，RNN神经网络的每个神经元
通过输入值和上一时刻的记忆值同时乘对
应权重并与偏差相加，最终再通过sigmoid激活函数将结果压缩在 0 和 1 之间得到输出。
上述过程得到如下所示公式：
$$h_t=\sigma(Wx_t+Uh_{t-1}+b)$$

公式中W代表权重，b是偏差，$x_t$是t时刻的神经元输入值，$h_{t-1}$是t-1时刻神经
元的记忆输出值，W和U为对应的值的权重，$h_t$是当前神经元的输出值。训练时
对每个神经元采用反向传播(BP)算法，使用训练集中的数据，通过指定学习优化器和损失函数
来迭代计算权重和偏差，从而使误差的最小化。

由循环神经网络的结构和原理也可以看到，由于其在训练反向传播时权重产生的误差都会累加
迭代，因而很容易误差累加数值过大，造成梯度爆炸。同时，由sigmoid激活函数的性质可知，当
值较大时，函数趋于1，并变得平缓，此时进行反向传播会造成整体值过小，造成梯度消失的问题。另外，
循环神经网络的训练过程中每个神经元权重都是直接记忆学习临近时刻的，因而对可能会存在的如
季节性效应等长期关系学习不佳。

上述经典RNN的三个问题中，梯度爆炸可以采用阈值范围对梯度进行裁剪就可以解决，但是梯度消失和
长期依赖关系的问题则必须要改变模型的结构。LSTM是首先被提出的解决方案
\upcite{hochreiter1997long}，GRU则是相对于LSTM更简单且更优异的方案。

\subsection{GRU}
GRU是由Cho等人于2014年提出的一种类似于LSTM的神经网络模型\upcite{cho2014learning}。
本文之所以选择GRU而非LSTM，是因为相较于LSTM的结构，即三个门控单元输入门、遗忘门和输出门，
GRU只有两个，分别为更新门和重置门。并且GRU的单个神经元中并不会保留内部记忆，
因而GRU的参数更少，复杂度更低，收敛速度更快，并且GRU和LSTM所能达到的训练以及预测
效果同样出色，因而总体而言GRU要更优秀\upcite{chung2014empirical}。

GRU的工作原理如下：

首先更新门确定有多少过去的信息（来自之前的时刻）需要传递到未来。计算时刻t的更新
门 $z_t$的值，执行计算公式如下：
$$z_t=\sigma(W^{(z)}x_t+U^{(z)}h_{t-1})$$

该公式和经典RNN的计算公式类似。

重置门决定要忘记多少过去的信息，其公式与更新门的公式相同：
$$r_t=\sigma(W^{(r)}x_t+U^{(r)}h_{t-1})$$

然后执行以下计算公式：
$$h^{\prime}_t=tanh(Wx_t+r_t\odot Uh_{t-1})$$

该步骤中重置门和过去的神经元输出进行元素积，确定遗忘掉多少过去的信息
，并和当前的输入值进行整理相加。在此步中，若选择使$r_t$（重置门）的值
接近0，则可以遗忘掉过去的大部分信息。

最后一步，确定当前步骤需要记忆的信息：
$$h_t=z_t\odot r_t+(1-z_t)\odot h^{\prime}_t$$

该模型可以选择使$z_t$（更新门）的值接近1，从而保留大部分过去的信息
。并且由于此时$1-z_t$接近0，因而将忽略对当前内容的记忆。

从上述推导步骤可以看到GRU模型解决了长期记忆的问题。同时，更新门和重置门的权重
接近1和接近0的同时出现也缓解了梯度消失和梯度爆炸的问题。

从上述推导过程还可以得出，如果选择将重置门设置为1，更新门设置为0，那么此时GRU将
等效于经典的 RNN 模型。

\chapter{模型的建立和评估}
\section{六种特征数据的ICEEMDAN分解}
下述ICEEMDAN分解代码请见附录部分A.4。

这里使用python的pyEMD库实现ICEEMDAN分解\footnote{尽管pyEMD库中调用方法和类名为CEEMDAN，
但根据官方文档，其内部实现时是采用的改进的CEEMDAN，即ICEEMDAN发表论文中所述算法。}，并使用
numpy库相关方法进行傅里叶变换，生成幅频。最终使用Matplotlib进行可视化作图。

图中第一行为原始数据，最后一行为ICEEMDAN分解后得到的残差，中间的行为ICEEMDAN分解后得到的
本征模函数（IMF）分量。其中，每行左侧为原始得到的时域数据，横坐标范围为[0,5831]，单位为三小时（3hr）。
右侧为经过傅里叶变换后得到的频域数据，横坐标范围为[0,2915]，单位为赫兹（HZ）。

\begin{itemize}
    \item[1. ] 地面向下长波辐射
\end{itemize}

\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/lrad.pdf}
    \caption{地面向下长波辐射的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_lrad}
\end{figure}

从图\ref{fig_lrad}中可以看到，原始信号中高频噪声含量较高。ICEEMDAN将地面向下长波辐射
的原始时间序列分解为10个本征模函数（IMF）分量，分解效果显著。由幅频可以看出，高频噪声
主要集中在IMF1分量和IMF2分量中，集中于500HZ-3000HZ处。

\begin{itemize}
    \item[2. ] 近地面气压
\end{itemize}

\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/pres.pdf}
    \caption{近地面气压的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_pres}
\end{figure}

从图\ref{fig_pres}中可以看到，原始信号中高频噪声含量同样较高。ICEEMDAN将近地面气压
的原始时间序列分解为9个本征模函数（IMF）分量，分解效果显著。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于500HZ-2300HZ处。

\begin{itemize}
    \item[3. ] 近地面空气相对湿度
\end{itemize}

\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/shum.pdf}
    \caption{近地面空气相对湿度原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_shum}
\end{figure}

从图\ref{fig_shum}中可以看到，原始信号中高频噪声含量也较高。ICEEMDAN将近地面空气相对湿度
的原始时间序列分解为10个本征模函数（IMF）分量，分解效果较好。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于750HZ-3000HZ处。

\begin{itemize}
    \item[4. ] 地面向下短波辐射
\end{itemize}

\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/srad.pdf}
    \caption{地面向下短波辐射的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_srad}
\end{figure}

从图\ref{fig_srad}中可以看到，原始信号中高频噪声含量也较高。ICEEMDAN将地面向下短波辐射
的原始时间序列分解为10个本征模函数（IMF）分量，分解效果十分显著。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于750HZ-2200HZ处。

\begin{itemize}
    \item[5. ] 近地面气温
\end{itemize}

\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/temp.pdf}
    \caption{近地面气温的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_temp}
\end{figure}

从图\ref{fig_temp}中可以看到，原始信号中高频噪声含量同样较高。ICEEMDAN将近地面气温
的原始时间序列分解为8个本征模函数（IMF）分量，分解效果显著。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于500HZ-2200HZ处。

\begin{itemize}
    \item[6. ] 近地面全风速
\end{itemize}

\begin{figure}[H]
    \centering
    \includegraphics[width=1\textwidth]{figures/wind.pdf}
    \caption{近地面全风速的原始数据、ICEEMDAN分解IMF分量、残差（左）及对应幅频图（右）}
    \label{fig_wind}
\end{figure}

从图\ref{fig_wind}中可以看到，原始信号中高频噪声含量也较高。ICEEMDAN将近地面全风速
的原始时间序列分解为11个本征模函数（IMF）分量，分解效果显著。由幅频可以看出，高频噪声
主要集中在IMF1和IMF2分量中，集中于500HZ-3000HZ处。

将上述信号中高频噪声对应的IMF分量去除，剩余的低频信号IMF分量相加，即可得到经过ICEEMDAN
分解的时间序列信号。

\section{搜寻Prophet模型最优超参数}
将时间序列数据作为输入，使用Prophet自带的实现方法，对数据进行交叉验证，
通过MAPE值评估12小时的预测性能，为超参数调优提供依据。首先选择前438天
（3504条数据）作为初始训练数据。对于后291天（2324条数据），每隔1天逐步对
未来12小时的情况进行一次预测，共计验证291次，搜寻Prophet的最优超参数，从而使得平均绝对
误差百分比（MAPE）值最小化。使用的代码见附录部分A.5。最终得到对于风速序列的最优参数
如表\ref{prophet_param}所示：

\begin{table}[H]
    \centering
    \caption{风速历史时间序列数据Prophet模型的最优超参数}
    \begin{tabular}{cc}
    \toprule
    超参数名 & 值 \\
    \midrule
    changepoint\_prior\_scale & 1.0 \\
    seasonality\_prior\_scale & 0.1 \\
    seasonality\_mode & additive \\
    changepoint\_range & 1 \\
    \bottomrule
    \end{tabular}
    \label{prophet_param}
\end{table}

\section{基于风速历史时间序列数据的ICEEDMAN-GRU模型}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/ICEEMDAN-GRU-Wind.pdf}
    \caption{基于风速历史时间序列数据的ICEEDMAN-GRU模型结构图}
    \label{fig_ICEEMDAN_GRU_Wind}
\end{figure}

图\ref{fig_ICEEMDAN_GRU_Wind}展示了基于风速历史时间序列数据的ICEEDMAN-GRU模型结构示意
。该模型使用了历史风速时间序列中的5828条数据点，以8个连续时间序列数据点（24小时，1天）为
一个时间窗口制作为一个训练样本。每个时间窗口中的数据点整体为一个输入，每个时间窗口中的输出
为该输入窗口紧挨着的下一个时间序列数据点（3小时）的预测值。因而总共得到5820个训练样本
（时间窗口），每个时间窗口样本中数据点都与上一个时间窗口中对应的数据点相差3小时。

将上述5820个训练样本的输入值（5820，8）首先通过标准化后，进行RBF核主成分分析升维，降低
复杂度，得到（5820，5810）的输入矩阵。随后将其变形为（5820，1，5810）的输入矩阵，再将其
输入进GRU模型。

本文使用的GRU模型网络结构如图\ref{fig_gru}所示：

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/wind_grumodel_plot.pdf}
    \caption{本文使用的GRU模型网络结构图}
    \label{fig_gru}
\end{figure}

该模型四层之间使用序贯模型的形式进行连接。第一层为模型的输入层，每次输入一个（1，5810）的
向量，代表一个样本的时间窗口。第二层为使用标准GRU模型单元（即激活函数为sigmoid，
循环激活函数为tanh）的隐藏层，其一共有1024个GRU单元，输出为（1，1024）的向量，可训练参数
共计21000192个。第三层使用将激活函数和循环激活函数都改为GELU的GRU单元，其共计512个GRU单
元，输出为（1，512）的向量，可训练参数为2362368个。第四层为输出层，将前一层的输出值通过全连
接的方式，得到（1，1）的向量，可训练参数513个。整个模型可训练参数
共计23363073个，输出最终预测值。

进行预测时使用多步预测的方法。每个时间窗口的输入为现在已知的数据点值，混合上一个时间窗口的
预测输出值，从而进行四步预测（12小时）。

\section{基于风速历史时间序列数据的ICEEDMAN-Prophet-GRU模型}
\begin{figure}[H]
	\centering
    \includegraphics[width=1\textwidth]{figures/ICEEMDAN-Prophet-GRU-Wind.pdf}
    \caption{基于风速历史时间序列数据的ICEEDMAN-Prophet-GRU模型结构图}
    \label{fig_ICEEMDAN_Prophet_GRU_Wind}
\end{figure}

如图\ref{fig_ICEEMDAN_Prophet_GRU_Wind}所示，本模型在基于风速历史时间序列数据的
ICEEDMAN-GRU模型基础上，将每个窗口的输入值同时使用Prophet框架进行统计分析处理，得到
该窗口数据对应的拟合值、趋势分量、累加式季节性分量以及上述分量所对应的预测最大边界和最
小边界共计9个特征，并与原始数据进行拼接整合，得到（5820，8，10）的矩阵。随后将后两个
维度展平，生成的（5820，80）矩阵进行数据标准化缩放，再通过使用RBF核函数的核
主成分分析（KPCA），将训练集升维至（5820，5819），变形之后再输入进入同基于风速历史
时间序列数据的ICEEDMAN-GRU模型中结构相同的GRU模型，从而
得到最终的预测结果。

\section{多特征ICEEDMAN-Prophet-GRU-NN模型}
\begin{figure}[H]
	\centering
    \includegraphics[width=0.9\textwidth]{figures/ICEEMDAN-Prophet-GRU-All-Features.pdf}
    \caption{多特征ICEEDMAN-Prophet-GRU-NN模型结构图}
    \label{fig_ICEEMDAN_Prophet_GRU_All_Features}
\end{figure}
图\ref{fig_ICEEMDAN_Prophet_GRU_All_Features}展示了多特征ICEEDMAN-Prophet-GRU-NN模型结构。
该模型将地面向下长波辐射、近地面气压、近地面空气相对湿度、地面向下
短波辐射、近地面气温，和近地面全风速6种气象要素的原始历史数据的每个气象要素通过和
对风速历史时间序列数据的ICEEDMAN-Prophet-GRU模型一致的处理方式，得到每个气象要素的窗口样本
的GRU模型预测值（5820，1，6），再将这些预测值通过使用RBF核函数的核主成分分析（KPCA），
将其升维至（5820，1，4260），随后使用如图\ref{fig_gru_nn}所示的NN模型将这些预测值输入，得到
最终的对风速的预测结果。

\begin{figure}[H]
	\centering
    \includegraphics[width=0.5\textwidth]{figures/all_feature_prophet_gru_nnmodel_plot.pdf}
    \caption{多特征ICEEDMAN-Prophet-GRU-NN模型中使用的NN模型网络结构图}
    \label{fig_gru_nn}
\end{figure}

该神经网络模型（NN）六层之间使用序贯模型的形式进行连接。第一层为模型的输入层，每次输入一个（1，4260）的
向量。第二层为一个展平（Flatten）层，将输入展平为（4260）。第三、四层均为全连接层，其激活函数均为GELU，
各有128、64个神经元，输出为（64）的向量，可训练参数分别为555776个和8256个。第五层为随机丢弃层（DropOut层），
其丢弃比率为20\%，用于防止神经网络的过拟合。最后一层为输出层，将前一层的输出值通过全连
接的方式，得到最后结果，可训练参数65个。整个模型可训练参数共计564097个，输出最终预测值。
代码部分见附录部分A.7。

\section{模型评价指标公式}
下述指标公式使用scikit-learn自带的方法实现，并和15\%准确率（预测值和真实值实际偏差在15\%以内的样本数和
总样本数的比值）封装为print\_metrics函数调用，相关代码见附录部分A.6。
\begin{itemize}
\item[1. ] 均方误差（MSE）
$$MSE=\frac{1}{N}\sum_{t=1}^{N}\left(\hat{y}\left(t\right)-y\left(t\right)\right)^2$$

\item[2. ] 平均绝对误差（MAE）
$$MAE=\frac{1}{N}\sum_{t=1}^{N}\left|\hat{y}\left(t\right)-y\left(t\right)\right|$$

\item[3. ] 平均绝对误差百分比（MAPE）
$$MAPE=\frac{1}{N}\sum_{t=1}^{N}\left|\frac{\hat{y}\left(t\right)-y\left(t\right)}{y\left(t\right)}\right|$$

\item[4. ] 均方根误差（RMSE）
$$RMSE=\sqrt{\frac{1}{N}\sum_{t=1}^{N}\left(\hat{y}\left(t\right)-y\left(t\right)\right)^2}$$

上述四种误差指标均为，当对应指标值越小时，模型的精度越高。

\item[5. ] 决定系数（$R^2$）
$$R^2=1-\frac{\sum_{t=1}^{N}(\hat{y}\left(t\right)-y\left(t\right))^2}{\sum_{t=1}^{N}(\bar{y}\left(t\right)-y\left(t\right))^2}$$

决定系数（$R^2$）取值范围为$(-\infty, 1]$，越接近1代表模型的准确度越好。
\end{itemize}

\section{模型的对比评估}

\begin{table}[H]
    \centering
    \caption{五种模型在测试集中四步预测12小时风速指标对比评估}
    \begin{tabular}{lcccccc}
    \toprule
    模型名称 & MAPE & MAE & MSE & RMSE & $R^2$ & 15\% \\
    \midrule
    基于风速的Prophet模型 & 0.7599 & 1.5475 & 2.4874 & 1.5771 & -14.4053 & 0 \\
    基于风速的ICEEMDAN-Prophet模型 & 0.7396 & 1.5054 & 2.3588 & 1.5359 & -13.6092 & 0 \\
    基于风速的ICEEMDAN-GRU模型 & 0.1671 & 0.3 & 0.2055 & 0.4533 & -0.2728 & 0.75 \\
    风速ICEEMDAN-Prophet-GRU模型 & 0.1356 & 0.286 & 0.1121 & 0.3349 & 0.3051 & 0.5 \\
    多特征ICEEMDAN-Prophet-GRU-NN & 0.0825 & 0.1734 & 0.0307 & 0.1751 & 0.81 & 1 \\
    \bottomrule \\
    \end{tabular} \\
    \label{models-metrics}
\end{table}

\begin{figure}[H]
	\centering
    \includegraphics[width=0.9\textwidth]{figures/prophet_wind.pdf}
    \caption{基于风速历史的Prophet模型可视化图}
    \label{fig_prophet_wind}
\end{figure}

图\ref{fig_prophet_wind}展示了基于风速历史的Prophet模型的可视化图，即模型在训练集上拟合的预测结果与实际
值的对比。该模型采用上述章节中搜寻得到的Prophet模型最优超参数，分析历史5828条数据从而直接预
测出未来12小时（4条）的风速值。
图中黑点部分为实际值，实蓝色曲线部分为预测值，透明蓝色部分的
上下边界分别为预测结果可能的最大值与最小值。从图中我们可以看到其实际值与预测值的偏差很大，结合
该图与表\ref{models-metrics}
中对未来4步预测数据评价指标值可知，Prophet模型的预测结果很差。这是因为Prophet模型类似于传统
的SARIMA模型，对主要具有线性关系的时间序列数据预测精度较高，但是对于主要具有复杂非线性关系，且波动性较强
的时间序列，其很难预测准确。从表\ref{models-metrics}中我们还可以看到，对风速数据进行ICEEMDAN分解
处理，剔除高频噪声后，降低了时间序列数据的复杂度，基于风速历史ICEEMDAN-Prophet模型的准确度相
较于未经分解的基于风速历史Prophet模型而言各项指标都有比较好的提升效果。

神经网络部分的实现使用Tensorflow Keras。对于所有GRU模型，为统一标准，选择训练10个epoch，
对于多特征ICEEMDAN-Prophet-GRU-NN中NN模型选择训练5000个epoch。批大小（Batch Size）
为默认32，训练过程中设置回调函数，当损失5步内不再下降时自动停止训练过程，并自动保存训练过程中
得到的损失最小的模型。损失函数为Huber，模型优化器为Nadam，设定学习率为0.001。

最终模型用于预测未来四步（12小时）风速的可视化情况见图\ref{fig_gru_predict_test}，最终模型四步预测的
评价指标数值见表\ref{models-metrics}。

\begin{figure}[H]
	\centering
	\subfloat[风速ICEEMDAN-GRU]{
        \includegraphics[width=0.33\textwidth]{figures/wind_gru_predict_test.pdf}
    }
	\subfloat[风速ICEEMDAN-Prophet-GRU]{
        \includegraphics[width=0.33\textwidth]{figures/wind_only_prophet_gru_predict_test.pdf}
    }
    \subfloat[多特征ICEEMDAN-Prophet-GRU]{
        \includegraphics[width=0.33\textwidth]{figures/all_feature_prophet_gru_predict_test.pdf}
    }
    \caption{三种基于本文提出的神经网络的模型四步预测（12小时）风速的可视化图}
    \label{fig_gru_predict_test}
\end{figure}

由图\ref{fig_gru_predict_test}和表\ref{models-metrics}可知，使用GRU模型之后，模型的各项
指标相较于只使用Prophet而言都得到了大幅度地显著提高。进一步地，加入Prophet的统计分析数据之后
交由GRU进行训练，模型的准确度和各项指标进一步提升，但是在进行第四步预测时都出现了预测值的较大
偏离问题。最终，使用多气象要素特征训练GRU模型，并将这些气象要素模型的预测结果输入进NN，从而对
风速的预测值进行校正，产生的预测结果MAPE值达到了个位数，准确率有了比较大的提升，且第四步预测时
准确度也较好，体现了多特征ICEEMDAN-Prophet-GRU-NN模型的优越性和实用价值。

\chapter{总结与展望}

本文综合使用目前最新的科研成果，具有如下优势和创新点：

\begin{itemize}
\item 从数值预报、大气动力学获得灵感，使用
多气象要素联合预测，同时预测其他具有强周期性、易预测的气象要素，
而不仅仅基于风速的历史时间序列，以达到对风速预测进行修正的目的。

\item 模型基于最新信号分解技术ICEEMDAN（2014年）\upcite{colominas2014improved}
，还采用Facebook推出的新型时间序列框架 Prophet（2018年）\upcite{taylor2018forecasting}
与最新循环神经网络 GRU 模型（2014年）\upcite{cho2014learning}进行组合。

\item 从支持向量回归机获得灵感，
将GRU模型的输入数据使用RBF核PCA升维，从而将非线性的特征历史数据映射到
高维线性可分，降低复杂度。

\item 对相关模型
进行优化，突破模型的传统，将GELU激活函数（2016年）\upcite{hendrycks2016gaussian}
以及Nadam优化器（2016年）\upcite{dozat2016incorporating}和Huber损失函数应用到短期
风速预测领域。

\item 通过选择甘肃酒泉的一个真实风力发电厂附近进行短期风速的
预测从而验证模型，而并非
像同类研究一样为了预测风速选择了任意的非风力发电场所的气象数据集进行验证，
因而本论文提出的模型通过了实用性的验证。最终预测结果显示了该模型的
优势和极大的实用价值。
\end{itemize}

因为论文时间紧迫，展望未来，本次论文写作过程也存在着许多遗憾的点，
如果有机会的话可以在后续进一步研究过程中完成：

\begin{itemize}
\item[1.] 本次建模过程出于性能的考虑，在源数据集1979-2018年份中只选择
了最后两年跨度的时间序列数据，没有将更大尺度的数据投入训练。对于更大尺度
数据而言，模型能进一步强化对年季节性和长期变化关系的学习，因而能够取得更
好的效果。
\item[2.] 由于Prophet搜寻最优超参数所耗费时间过长，本文只对风速原始时间
序列数据这一个模型进行了搜索最优超参数的过程，因为对于一个模型的超参数搜
寻在作者电脑中运行完成大概就要花上三、四天的时间，耗费时间太长，因而对于
其他特征时间序列本文则直接沿用了风速原始时间序列数据的最优超参数。如果对
每个特征的时间序列构建的Prophet模型都加以优化，预计会产生更好的效果。
\item[3.] 本文只选择了甘肃酒泉的一个真实风力发电厂附近的地点进行短期风速的
预测。当然本文作者坚信在其他风力发电场所本模型也会产生很好的效果，但后续有待验
证。
\item[4.] 受本文作者使用的电脑用于训练的显卡和CPU以及内存的限制，没有进一步
将本文提出模型中所用神经网络层数进一步加深，因而可以进一步探究加深后模型的表现。 
\item[5.] 随着数据科学的发展，新模型正在不断地涌现出来。由于单一的模型各有
优缺点，尝试更多各种不同的新型模型，用各种不同的方法组合起来，会产生更好的效果。 
\end{itemize}

%论文后部
\backmatter


%=======%
%引入参考文献文件
%=======%
\bibdatabase{bib/database}%bib文件名称 仅修改bib/ 后部分
\printbib
% \nocite{*} %显示数据库中有的，但是正文没有引用的文献


\Appendix

\section{数据集制作代码}

\begin{lstlisting}[language = python]
# 原始数据下载地址：
# https://www.tpdc.ac.cn/zh-hans/data/8028b944-daaa-4511-8769-965612652c49
# 登录FTP后下载Data_forcing_03hr_010deg文件夹中对应.gz文件解压得到.nc文件
from netCDF4 import Dataset
import datetime

# 甘肃中电酒泉第四风力发电有限公司
lat_index = 256
lon_index = 269
variable_list = ["lrad", "prec", "pres", "shum",
                    "srad", "temp", "wind"]
with open('data.csv', 'w') as f:
    f.write("ds")
    for variable in variable_list:
        f.write(',' + variable)
    f.write('\n')
    for year in range(2017, 2019):
        for month in range(1, 13):
            dataset = []
            time_data = []
            for name in variable_list:
                data = Dataset("data/" + name + 
                                "_ITPCAS-CMFD_V0106_B-01_03hr_010deg_"
                                + str(year) + str(month).zfill(2) +
                                ".nc")
                dataset.append(data.variables[name][:])
                time_data = data.variables['time'][:]

            for index in range(len(time_data)):
                f.write(datetime.datetime.utcfromtimestamp(
                    (time_data[index]-613608)*3600).strftime(
                        "%Y-%m-%d %H:%M:%S"))
                for data in dataset:
                    f.write(',' + str(
                            data[index][lat_index][lon_index]))
                f.write('\n')
\end{lstlisting}

\section{表\ref{analysis} 中的数据源制作代码}

\begin{lstlisting}[language = python]
import pandas as pd
data = pd.read_csv('data.csv')
stat = data.describe()
stat.loc['range'] = stat.loc['max']-stat.loc['min']
stat.loc['dis'] = stat.loc['75%']-stat.loc['25%']
stat.loc['var'] = stat.loc['std']/stat.loc['mean']
stat.loc['mad'] = data.mad()
stat.loc['skew'] = data.skew()
stat.loc['kurt'] = data.kurt()
print(stat)
\end{lstlisting}

\section{表\ref{relativity-analysis} 中的数据源制作代码}

\begin{lstlisting}[language = python]
from scipy import stats
for item in ['lrad', 'prec', 'pres', 'shum', 'srad', 'temp']:
    print(stats.spearmanr(
          data[[item]].to_numpy().ravel(),
          data[['wind']].to_numpy().ravel()))
\end{lstlisting}

\section{ICEEMDAN分解以及分解数据的存储}

\begin{lstlisting}[language = python]
import numpy as np
from PyEMD import CEEMDAN
IImfs=[]
def ceemdan_decompose_res(data, trials=100, epsilon=0.005, noise_scale=1, noise_kind="normal", range_thr=0.01, total_power_thr=0.05):
    ceemdan = CEEMDAN(parallel=True, processes=8, trials=trials, epsilon=epsilon, noise_scale=noise_scale, noise_kind=noise_kind, range_thr=range_thr, total_power_thr=total_power_thr)
    ceemdan.ceemdan(data)
    imfs, res = ceemdan.get_imfs_and_residue()
    for i in range(imfs.shape[0]):
        IImfs.append(imfs[i])
    return res
count = 0
for name in ["lrad", "prec", "pres", "shum", "srad", "temp", "wind"]:
    input_data = data[name].to_numpy().ravel()
    ceemdan_decompose_res(input_data)
    with open(name + '.csv', 'w') as f:
        f.write("ds")
        for i in range(1, len(IImfs)-count+1):
            f.write(',IMF' + str(i))
        f.write('\n')
        for n in range(len(input_data)):
            f.write(data['ds'][n])
            for index in range(count, len(IImfs)):
                f.write(',' + str(IImfs[index][n]))
            f.write('\n')
    count=len(IImfs)

imf_dic={'lrad':2, 'pres':2, 'shum':2, 'srad':2, 'temp':2, 'wind':2}
data_decomposed = pd.DataFrame()
data_decomposed['ds'] = data['ds']
for feature in imf_dic.keys():
    data_iceemdan = pd.read_csv(feature+'.csv')
    temp = pd.DataFrame({feature:[0.0 for _ in range(len(data_iceemdan))]})
    for index in data_iceemdan.columns:
        if index.startswith('IMF') and imf_dic[feature] < int(index.lstrip('IMF')):
            temp[feature] += data_iceemdan[index]
    data_decomposed=data_decomposed.join(temp)
data_decomposed.to_csv('data_decomposed.csv')
\end{lstlisting}

\section{基于风速历史时间序列数据的Prophet模型的参数交叉验证调优}

\begin{lstlisting}[language = python]
import itertools
from prophet import Prophet
from prophet.diagnostics import cross_validation
from prophet.diagnostics import performance_metrics
param_grid = {  
    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5, 1.0, 10.0, 100.0, 1000.0, 10000.0],
    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0, 100.0, 1000.0, 10000.0],
    'seasonality_mode': ['additive', 'multiplicative'],
    'changepoint_range': [0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]
}

all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]
mapes = []

df = pd.DataFrame(data['ds'])
df['y'] = data['wind']

for params in all_params:
    m = Prophet(yearly_seasonality=True, **params).fit(df)
    df_cv = cross_validation(m, initial='438 days', period='1 days', horizon = '12H', parallel="processes")
    df_p = performance_metrics(df_cv, rolling_window=1)
    mapes.append(df_p['mape'].values[0])

tuning_results = pd.DataFrame(all_params)
tuning_results['mape'] = mapes

best_params = all_params[np.argmin(mapes)]
print(best_params)
\end{lstlisting}

\section{模型评价指标计算实现代码}

\begin{lstlisting}[language = python]
from sklearn import metrics
def print_metrics(pred, y_vals):
    print('mape: ', metrics.mean_absolute_percentage_error(y_vals, pred))
    print('mae: ', metrics.mean_absolute_error(y_vals, pred))
    print('mse: ', metrics.mean_squared_error(y_vals, pred))
    print('rmse: ', np.sqrt(metrics.mean_squared_error(y_vals, pred)))
    print('r2: ', metrics.r2_score(y_vals, pred))
    count = 0
    y_error = pred.flatten() - y_vals.flatten()
    y_error = np.array([abs(e) for e in y_error]).flatten()
    for i in range(len(y_error)):
        if(y_error[i] < 0.15 * y_vals[i]):
            count += 1
    print('15% 准确度: ', count / len(pred))
\end{lstlisting}

\section{多特征ICEEDMAN-Prophet-GRU-NN模型实现代码和指标计算}

\begin{lstlisting}[language = python]
# ICEEDMAN
data = pd.read_csv('data_decomposed.csv')
split_line = 5828
window = 8
y_row_list = []
weather_features = ["lrad", "pres", "shum", "srad", "temp", "wind"]
for row in range(split_line-window):
    y_row_list.append(dict(("y"+weather_feature,data[weather_feature][row+window]) for weather_feature in weather_features))
y=pd.DataFrame(y_row_list)

from sklearn.preprocessing import StandardScaler
yscaler = StandardScaler()
y_train = yscaler.fit_transform(y.to_numpy())

# Prophet
features = ['trend', 'yhat_lower', 'yhat_upper', 'trend_lower', 'trend_upper', 'additive_terms',
            'additive_terms_lower', 'additive_terms_upper', 'yhat']
X=np.empty((0,(len(features)+1)*window*len(weather_features)))
for row in range(split_line-window):
    temp_array=np.empty((1,0))
    for weather_feature in weather_features:
        temp_df = pd.DataFrame(data['ds'][row:row+window])
        temp_df['y'] = data[weather_feature][row:row+window]
        m = Prophet(changepoint_prior_scale=1.0, seasonality_prior_scale=0.1, seasonality_mode='additive', changepoint_range=1)
        m.fit(temp_df)
        future = m.make_future_dataframe(periods=1, freq='3H')
        forecast = m.predict(future)
        forecast = forecast[features].to_numpy()[:-1]
        forecast = np.append(forecast, np.array([data[weather_feature][row+i] for i in range(window)]).reshape(-1,1), axis=1)
        forecast = forecast.flatten()
        forecast = forecast.reshape(1,-1)
        temp_array=np.append(temp_array, forecast, axis=1)
    X=np.append(X, temp_array, axis=0)

# GRU
from sklearn.decomposition import KernelPCA
from tensorflow import keras
modelname='all_feature_prophet_gru'
scaler_list=[]
pca_list=[]
data_list=[]
model_list=[]
for weather_feature_index in range(len(weather_features)):
    modelfname=modelname+ '_' + weather_features[weather_feature_index]
    scaler = StandardScaler()
    scaler_list.append(scaler)
    X_train = scaler.fit_transform(X.reshape(split_line-window,len(weather_features),window,-1)[:,weather_feature_index].reshape(split_line-window,-1))
    pca = KernelPCA(kernel='rbf')
    pca_list.append(pca)
    X_train = pca.fit_transform(X_train)
    X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))
    data_list.append(X_train)
    model = keras.models.Sequential()
    model.add(keras.layers.GRU(1024,input_shape = (1, X_train.shape[2]),return_sequences = True))
    model.add(keras.layers.GRU(512,activation = 'gelu', recurrent_activation = 'gelu',return_sequences = True))
    model.add(keras.layers.Dense(1))
    es_callback = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True, monitor="loss")
    model.compile(loss = keras.losses.Huber(), optimizer = keras.optimizers.Nadam(0.001))
    model.summary()
    keras.utils.plot_model(model, to_file=modelfname+'model_plot.pdf', show_shapes=True, show_layer_names=True)
    print(weather_features[weather_feature_index])
    history=model.fit(X_train, y_train[:,weather_feature_index].reshape(-1,1), epochs = 10, verbose = 1, shuffle = True, callbacks = [es_callback])
    model_list.append(model)

row_list = y_row_list.copy()
for pointer in range(X.shape[0],len(data)-split_line+X.shape[0]):
    gru_output=np.empty((1,1,0))
    for weather_feature_index in range(len(weather_features)):
        input_np = np.array([row_list[row]['y'+weather_features[weather_feature_index]] for row in range(pointer-window, pointer)])
        temp_df = pd.DataFrame(data['ds'][pointer:pointer+window])
        temp_df['y'] = input_np
        m = Prophet(changepoint_prior_scale=1.0, seasonality_prior_scale=0.1, seasonality_mode='additive', changepoint_range=1, n_changepoints=window-1)
        m.fit(temp_df)
        future = m.make_future_dataframe(periods=1, freq='3H')
        forecast = m.predict(future)
        forecast = forecast[features].to_numpy()[:-1]
        forecast = np.append(forecast, np.array([row_list[row]['y'+weather_features[weather_feature_index]] for row in range(pointer-window, pointer)]).reshape(-1,1), axis=1)
        forecast = forecast.flatten().reshape(1,-1)
        input_np = scaler_list[weather_feature_index].transform(forecast)
        input_np = pca_list[weather_feature_index].transform(input_np)
        input_np = np.reshape(input_np, (input_np.shape[0], 1, input_np.shape[1]))
        output_np = model_list[weather_feature_index].predict(input_np)
        gru_output=np.append(gru_output, output_np, axis=2)
    row_list.append(dict(("y"+weather_features[index],yscaler.inverse_transform(gru_output)[:,:,index][0][0]) for index in range(len(weather_features))))
predictions = yscaler.transform(pd.DataFrame(row_list)[X.shape[0]:].to_numpy()).reshape(-1,1,len(weather_features))
y_train = y.to_numpy()[:,-1]

gru_output=np.empty((X.shape[0],1,0))
for index in range(len(data_list)):
    predicted = model_list[index].predict(data_list[index])
    predicted = predicted[:,:,-1].reshape(X.shape[0],1,-1)
    gru_output=np.append(gru_output, predicted, axis=2)

# NN
model = keras.models.Sequential()
model.add(keras.layers.Flatten(input_shape=(1, len(weather_features))))
model.add(keras.layers.Dense(128, activation='gelu'))
model.add(keras.layers.Dense(64, activation='gelu'))
model.add(keras.layers.Dropout(0.2))
model.add(keras.layers.Dense(1))
es_callback = keras.callbacks.EarlyStopping(patience = 5, restore_best_weights = True, monitor="loss")
model.compile(loss = keras.losses.Huber(), optimizer = keras.optimizers.Nadam(0.001))
model.summary()
keras.utils.plot_model(model, to_file=modelname+'model_plot.pdf', show_shapes=True, show_layer_names=True)
history=model.fit(gru_output, y_train.reshape(-1,1,1), epochs = 5000, verbose = 1, shuffle = True, callbacks = [es_callback])

predicted = model.predict(gru_output).flatten()
predicted[predicted < 0] = 0
predictions = model.predict(predictions).flatten()
predictions[predictions < 0] = 0
print_metrics(predictions, data["wind"][split_line:].to_numpy())

generated = pd.DataFrame(data['ds'])[window:]
generated['y_pred'] = np.append(predicted, predictions)
generated['y_real'] = np.array(pd.DataFrame(data['wind'])[window:])
generated.to_csv(modelname + ".csv")
\end{lstlisting}

\Thanks

时光荏苒，岁月如梭。转眼间，近四年的本科生活就要结束了。这四年是充满了挑战
和挫折的四年，同时也是充实着丰收和果实的四年。值此毕业论文致谢之际，
我首先需要特别感谢的是我的毕业论文指导老师，兰州大学信息科学与工程学院的任超
副教授。任老师治学严谨，对我的论文写作极其认真负责。每当我遇到困难请教任老师
时，任老师总能事无巨细地耐心讲解。同时，任老师极高的专业素养与渊博的学识也十分
令我钦佩！在任老师带领的论文写作过程中，我的科研素养得到了极大地提高，获得了许多
十分宝贵的知识和经验。

其次，我要感谢兰州大学提供的一流教学环境与教育资源，兰州大学信息科学与工程
学院的各位老师的专业教导，兰州大学信息科学与工程学院2018级计算机科学与技术
基础理论班的各位同学，以及大气科学专业的舍友，和其他同学的支持与鼓励。四年的朝夕相处，是他们
让我拓宽了视野，掌握了基本的计算机专业知识和技能，并且让我获得了学习的动力，
为我的继续深造以及未来工作打好了坚实的基础，从而让我能够更好地为社会贡献自己
的力量。在后续的学习工作生活中，我必将以梦为马，不负韶华！

最后，我要感谢大学四年父母对我的默默关爱和支持，让我能够顺利地完成本科学业。
父母对我的无私且伟大的爱，是我在黑暗中的灯塔，给予了我不断前行的动力。

另外，本文使用的数据集下载于“国家青藏高原科学数据中心”(http://data.tpdc.ac.cn)。
在写作时从GitHub中获取并参考了兰州大学2016级物理科学与技术学院本科生余航
制作的“兰州大学本科生2021学士学位毕业论文LaTeX模板”，在此也一并致谢。

\rightline{}
\rightline{蒋嵩林}

\rightline{2022年5月于兰州大学榆中校区萃英山下}

%=====%
%论文（设计）成绩
%=====%

% 下面这些注释掉可以去掉成绩、评语什么的
\supervisorcomment{}


\committeecomment{}

\finalgrade{}
% 上面这些注释掉可以去掉成绩、评语什么的

% 下面的才是成绩页，上面是填写
\mainmatter
\pagenumbering{gobble}
\Grade
\clearpage

\end{document}